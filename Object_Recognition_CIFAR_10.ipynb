{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Recognition on CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IPGgH14l4rsj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import pylab\n",
    "\n",
    "if not os.path.isdir('figures'):\n",
    "    print('creating the figures folder')\n",
    "    os.makedirs('figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3620,
     "status": "ok",
     "timestamp": 1604954420632,
     "user": {
      "displayName": "Mu Siyi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8QgmJnhwClZ56sAt7RQhY0GcJe4BfDK1dGxf4ZQ=s64",
      "userId": "04695566065545999051"
     },
     "user_tz": -480
    },
    "id": "qM6Pm_to5Dxg",
    "outputId": "de7c85e4-ef92-4be5-adbd-12979d0e1c10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xi4CzOJd5Fvv"
   },
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        try:\n",
    "            samples = pickle.load(fo)\n",
    "        except UnicodeDecodeError:  # python 3.x\n",
    "            fo.seek(0)\n",
    "            samples = pickle.load(fo, encoding='latin1')\n",
    "\n",
    "    data, labels = samples['data'], samples['labels']\n",
    "\n",
    "    data = np.array(data, dtype=np.float32) / 255\n",
    "    labels = np.array(labels, dtype=np.int32)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCuFvgr_5HjH"
   },
   "outputs": [],
   "source": [
    "def make_model(num_ch_c1, num_ch_c2, use_dropout):\n",
    "    model = tf.keras.Sequential()\n",
    "    # Input layer: 32x32x3\n",
    "    model.add(layers.Input(shape=(3072, )))\n",
    "    model.add(layers.Reshape(target_shape=(32, 32, 3), input_shape=(3072,)))\n",
    "    # Convolution layer C1\n",
    "    model.add(layers.Conv2D(num_ch_c1, kernel_size=9, padding='valid', activation='relu', use_bias=True, input_shape=(None, None, 3)))\n",
    "    # Max pooling layer S1\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "    # Convolution layer C2\n",
    "    model.add(layers.Conv2D(num_ch_c2, kernel_size=5, padding='valid', activation='relu', use_bias=True))\n",
    "    # Max pooling layer S2\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "    # Flattern before fully-connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    # Dropout layer 1\n",
    "    if use_dropout:\n",
    "        model.add(layers.Dropout(rate = 0.5))\n",
    "    # Fully-connected layer F3\n",
    "    model.add(layers.Dense(300, activation = None))\n",
    "    # Dropout layer 2\n",
    "    if use_dropout:\n",
    "        model.add(layers.Dropout(rate = 0.5))\n",
    "    # Fully-connected layer F4\n",
    "    model.add(layers.Dense(10, use_bias=True, input_shape=(300,)))  # Here no softmax because we have combined it with the loss\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bpTKWsqA5J8W"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    '''Question 2'''\n",
    "    num_ch_c1 = 90  #10 30 50 70 90\n",
    "    num_ch_c2 = 100  #20 40 60 80 100 \n",
    "\n",
    "    epochs = 1000  \n",
    "    batch_size = 128  \n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    '''Question 3'''\n",
    "    optimizer_ = 'SGD' #'Adam' #'RMSProp' #'SGD-momentum' '  \n",
    "    use_dropout = True # False   \n",
    "\n",
    "    model = make_model(num_ch_c1, num_ch_c2, use_dropout)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    if optimizer_ == 'SGD':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer_ == 'SGD-momentum':  # Question 3(a)\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum = 0.1)\n",
    "    elif optimizer_ == 'RMSProp':  # Question 3(b)\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer_ == 'Adam':  # Question 3(c)\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise NotImplementedError(f'You do not need to handle [{optimizer_}] in this project.')\n",
    "\n",
    "    # Training and test\n",
    "    x_train, y_train = load_data('data_batch_1')\n",
    "    x_test, y_test = load_data('test_batch_trim')\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_test.shape)\n",
    "\n",
    "    # Training\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
    "    history = model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test))\n",
    "\n",
    "    # Creates a model that will return the outputs for conv and pooling layers\n",
    "    layer_outputs = [layer.output for layer in model.layers[1:5]] \n",
    "    activation_model = models.Model(inputs=model.input, outputs=layer_outputs) \n",
    "\n",
    "    # Names of the layers as title\n",
    "    layer_names = []\n",
    "    for layer in model.layers[1:5]:\n",
    "        layer_names.append(layer.name) \n",
    "    images_per_row = 10\n",
    "    \n",
    "    for i in range(2):\n",
    "        # Test image\n",
    "        plt.imshow(x_test[i, :].reshape(3,32,32).transpose(1,2,0))\n",
    "        plt.show()\n",
    "        \n",
    "        # Returns a list of 4 Numpy arrays: one array per layer activation\n",
    "        activations = activation_model.predict(x_test[i].reshape(1, 3072)) \n",
    "      \n",
    "        for layer_name, layer_activation in zip(layer_names, activations): \n",
    "            # Number of features in the feature map\n",
    "            n_features = layer_activation.shape[-1] \n",
    "            #The feature map has shape (1, size, size, n_features).\n",
    "            size = layer_activation.shape[1] \n",
    "            # Tiles the activation channels in this matrix\n",
    "            n_cols = n_features // images_per_row \n",
    "            display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "            for col in range(n_cols): \n",
    "                for row in range(images_per_row):\n",
    "                    channel_image = layer_activation[0,\n",
    "                                                    :, :,\n",
    "                                                    col * images_per_row + row]\n",
    "                    channel_image -= channel_image.mean()\n",
    "                    if channel_image.std() != 0:\n",
    "                        channel_image /= channel_image.std()\n",
    "                    channel_image *= 64\n",
    "                    channel_image += 128\n",
    "                    channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                    display_grid[col * size : (col + 1) * size, # Displays the grid\n",
    "                                row * size : (row + 1) * size] = channel_image\n",
    "            scale = 1. / size\n",
    "            plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                            scale * display_grid.shape[0]))\n",
    "            plt.title(layer_name)\n",
    "            plt.grid(False)\n",
    "            plt.imshow(display_grid, aspect='auto', cmap='gray')#cmap='viridis'\n",
    "            plt.show()\n",
    "            #plt.clf()\n",
    "\n",
    "    # Create folder to store models and results\n",
    "    if not os.path.exists('./models'):\n",
    "        os.mkdir('./models')\n",
    "    if not os.path.exists('./results'):\n",
    "        os.mkdir('./results')\n",
    "\n",
    "    # Save model\n",
    "    if use_dropout:\n",
    "        model.save(f'./models/{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout')\n",
    "    else:\n",
    "        model.save(f'./models/{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout')\n",
    "\n",
    "    \n",
    "    # Save the plot for losses\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    plt.plot(range(1, len(train_loss) + 1), train_loss, label='Train')\n",
    "    plt.plot(range(1, len(val_loss) + 1), val_loss, label='Test')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    if use_dropout:\n",
    "        plt.savefig(\n",
    "            f'./results/{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout_loss.pdf')\n",
    "    else:\n",
    "        plt.savefig(\n",
    "            f'./results/{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout_loss.pdf'\n",
    "        )\n",
    "    plt.close()\n",
    "\n",
    "    # Save the plot for accuracies\n",
    "    train_acc = history.history['accuracy']\n",
    "    test_acc = history.history['val_accuracy']\n",
    "    plt.plot(range(1, len(train_acc) + 1), train_acc, label='Train')\n",
    "    plt.plot(range(1, len(test_acc) + 1), test_acc, label='Test')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    if use_dropout:\n",
    "        plt.savefig(\n",
    "            f'./results/{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout_accuracy.pdf'\n",
    "        )\n",
    "    else:\n",
    "        plt.savefig(\n",
    "            f'./results/{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout_accuracy.pdf'\n",
    "        )\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 717817,
     "status": "ok",
     "timestamp": 1604955134843,
     "user": {
      "displayName": "Mu Siyi",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj8QgmJnhwClZ56sAt7RQhY0GcJe4BfDK1dGxf4ZQ=s64",
      "userId": "04695566065545999051"
     },
     "user_tz": -480
    },
    "id": "f9GDLnH_5NMH",
    "outputId": "cb2469af-7e6f-4e7b-cb36-9d1329e63dbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 24, 24, 90)        21960     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 90)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 100)         225100    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 100)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               480300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 730,370\n",
      "Trainable params: 730,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "(2000, 3072)\n",
      "(2000,)\n",
      "Epoch 1/1000\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 2.3024 - accuracy: 0.0949 - val_loss: 2.2912 - val_accuracy: 0.1135\n",
      "Epoch 2/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.2859 - accuracy: 0.1390 - val_loss: 2.2802 - val_accuracy: 0.1655\n",
      "Epoch 3/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.2762 - accuracy: 0.1763 - val_loss: 2.2710 - val_accuracy: 0.1920\n",
      "Epoch 4/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.2673 - accuracy: 0.1929 - val_loss: 2.2624 - val_accuracy: 0.2055\n",
      "Epoch 5/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.2582 - accuracy: 0.2070 - val_loss: 2.2529 - val_accuracy: 0.2245\n",
      "Epoch 6/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.2486 - accuracy: 0.2186 - val_loss: 2.2432 - val_accuracy: 0.2300\n",
      "Epoch 7/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.2384 - accuracy: 0.2237 - val_loss: 2.2328 - val_accuracy: 0.2390\n",
      "Epoch 8/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.2275 - accuracy: 0.2313 - val_loss: 2.2216 - val_accuracy: 0.2270\n",
      "Epoch 9/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.2158 - accuracy: 0.2342 - val_loss: 2.2090 - val_accuracy: 0.2555\n",
      "Epoch 10/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.2031 - accuracy: 0.2440 - val_loss: 2.1961 - val_accuracy: 0.2590\n",
      "Epoch 11/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.1899 - accuracy: 0.2475 - val_loss: 2.1819 - val_accuracy: 0.2660\n",
      "Epoch 12/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.1761 - accuracy: 0.2595 - val_loss: 2.1675 - val_accuracy: 0.2475\n",
      "Epoch 13/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.1619 - accuracy: 0.2566 - val_loss: 2.1530 - val_accuracy: 0.2600\n",
      "Epoch 14/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.1474 - accuracy: 0.2647 - val_loss: 2.1383 - val_accuracy: 0.2635\n",
      "Epoch 15/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.1331 - accuracy: 0.2709 - val_loss: 2.1234 - val_accuracy: 0.2675\n",
      "Epoch 16/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.1190 - accuracy: 0.2707 - val_loss: 2.1095 - val_accuracy: 0.2710\n",
      "Epoch 17/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.1054 - accuracy: 0.2715 - val_loss: 2.0959 - val_accuracy: 0.2735\n",
      "Epoch 18/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.0920 - accuracy: 0.2790 - val_loss: 2.0830 - val_accuracy: 0.2865\n",
      "Epoch 19/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.0798 - accuracy: 0.2833 - val_loss: 2.0706 - val_accuracy: 0.2940\n",
      "Epoch 20/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.0680 - accuracy: 0.2855 - val_loss: 2.0589 - val_accuracy: 0.2945\n",
      "Epoch 21/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.0571 - accuracy: 0.2896 - val_loss: 2.0471 - val_accuracy: 0.2855\n",
      "Epoch 22/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.0464 - accuracy: 0.2906 - val_loss: 2.0456 - val_accuracy: 0.2740\n",
      "Epoch 23/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.0368 - accuracy: 0.2932 - val_loss: 2.0311 - val_accuracy: 0.2685\n",
      "Epoch 24/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.0275 - accuracy: 0.2922 - val_loss: 2.0199 - val_accuracy: 0.2885\n",
      "Epoch 25/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.0188 - accuracy: 0.2954 - val_loss: 2.0304 - val_accuracy: 0.2650\n",
      "Epoch 26/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.0103 - accuracy: 0.3009 - val_loss: 1.9999 - val_accuracy: 0.3070\n",
      "Epoch 27/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.0020 - accuracy: 0.3032 - val_loss: 1.9943 - val_accuracy: 0.2910\n",
      "Epoch 28/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9939 - accuracy: 0.3002 - val_loss: 1.9885 - val_accuracy: 0.3100\n",
      "Epoch 29/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9874 - accuracy: 0.3021 - val_loss: 1.9817 - val_accuracy: 0.2945\n",
      "Epoch 30/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9792 - accuracy: 0.3075 - val_loss: 1.9741 - val_accuracy: 0.3015\n",
      "Epoch 31/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9717 - accuracy: 0.3075 - val_loss: 1.9741 - val_accuracy: 0.2920\n",
      "Epoch 32/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9654 - accuracy: 0.3136 - val_loss: 1.9588 - val_accuracy: 0.3120\n",
      "Epoch 33/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9589 - accuracy: 0.3127 - val_loss: 1.9499 - val_accuracy: 0.3215\n",
      "Epoch 34/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9521 - accuracy: 0.3168 - val_loss: 1.9408 - val_accuracy: 0.3230\n",
      "Epoch 35/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9454 - accuracy: 0.3153 - val_loss: 1.9468 - val_accuracy: 0.3170\n",
      "Epoch 36/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9398 - accuracy: 0.3193 - val_loss: 1.9308 - val_accuracy: 0.3175\n",
      "Epoch 37/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9334 - accuracy: 0.3197 - val_loss: 1.9455 - val_accuracy: 0.3075\n",
      "Epoch 38/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9288 - accuracy: 0.3228 - val_loss: 1.9225 - val_accuracy: 0.3200\n",
      "Epoch 39/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9224 - accuracy: 0.3216 - val_loss: 1.9240 - val_accuracy: 0.3060\n",
      "Epoch 40/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9179 - accuracy: 0.3234 - val_loss: 1.9237 - val_accuracy: 0.3210\n",
      "Epoch 41/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9129 - accuracy: 0.3276 - val_loss: 1.9783 - val_accuracy: 0.2795\n",
      "Epoch 42/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9091 - accuracy: 0.3266 - val_loss: 1.9123 - val_accuracy: 0.3140\n",
      "Epoch 43/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.9037 - accuracy: 0.3263 - val_loss: 1.9029 - val_accuracy: 0.3285\n",
      "Epoch 44/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8989 - accuracy: 0.3309 - val_loss: 1.9240 - val_accuracy: 0.3195\n",
      "Epoch 45/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8938 - accuracy: 0.3337 - val_loss: 1.9317 - val_accuracy: 0.3020\n",
      "Epoch 46/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.8917 - accuracy: 0.3291 - val_loss: 1.9487 - val_accuracy: 0.2965\n",
      "Epoch 47/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8864 - accuracy: 0.3369 - val_loss: 1.9141 - val_accuracy: 0.3050\n",
      "Epoch 48/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8822 - accuracy: 0.3333 - val_loss: 1.8971 - val_accuracy: 0.3275\n",
      "Epoch 49/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.8783 - accuracy: 0.3394 - val_loss: 1.8779 - val_accuracy: 0.3335\n",
      "Epoch 50/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.8734 - accuracy: 0.3352 - val_loss: 1.8796 - val_accuracy: 0.3305\n",
      "Epoch 51/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8698 - accuracy: 0.3435 - val_loss: 1.9177 - val_accuracy: 0.3155\n",
      "Epoch 52/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8671 - accuracy: 0.3415 - val_loss: 1.8779 - val_accuracy: 0.3375\n",
      "Epoch 53/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.8632 - accuracy: 0.3433 - val_loss: 1.8691 - val_accuracy: 0.3350\n",
      "Epoch 54/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.8599 - accuracy: 0.3460 - val_loss: 1.8912 - val_accuracy: 0.3195\n",
      "Epoch 55/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8557 - accuracy: 0.3456 - val_loss: 1.8728 - val_accuracy: 0.3325\n",
      "Epoch 56/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.8524 - accuracy: 0.3495 - val_loss: 1.8717 - val_accuracy: 0.3300\n",
      "Epoch 57/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.8493 - accuracy: 0.3459 - val_loss: 1.8571 - val_accuracy: 0.3340\n",
      "Epoch 58/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.8476 - accuracy: 0.3502 - val_loss: 1.8629 - val_accuracy: 0.3320\n",
      "Epoch 59/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8425 - accuracy: 0.3491 - val_loss: 1.8762 - val_accuracy: 0.3220\n",
      "Epoch 60/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.8404 - accuracy: 0.3493 - val_loss: 1.8437 - val_accuracy: 0.3455\n",
      "Epoch 61/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8354 - accuracy: 0.3531 - val_loss: 1.8498 - val_accuracy: 0.3505\n",
      "Epoch 62/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8329 - accuracy: 0.3587 - val_loss: 1.8530 - val_accuracy: 0.3420\n",
      "Epoch 63/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8295 - accuracy: 0.3583 - val_loss: 1.8680 - val_accuracy: 0.3170\n",
      "Epoch 64/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8276 - accuracy: 0.3563 - val_loss: 1.8751 - val_accuracy: 0.3210\n",
      "Epoch 65/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8246 - accuracy: 0.3556 - val_loss: 1.8333 - val_accuracy: 0.3395\n",
      "Epoch 66/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8200 - accuracy: 0.3599 - val_loss: 1.8305 - val_accuracy: 0.3480\n",
      "Epoch 67/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8169 - accuracy: 0.3582 - val_loss: 1.8336 - val_accuracy: 0.3375\n",
      "Epoch 68/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8156 - accuracy: 0.3636 - val_loss: 1.8162 - val_accuracy: 0.3580\n",
      "Epoch 69/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8107 - accuracy: 0.3605 - val_loss: 1.8651 - val_accuracy: 0.3455\n",
      "Epoch 70/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8109 - accuracy: 0.3620 - val_loss: 1.8258 - val_accuracy: 0.3530\n",
      "Epoch 71/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8075 - accuracy: 0.3622 - val_loss: 1.8488 - val_accuracy: 0.3345\n",
      "Epoch 72/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8026 - accuracy: 0.3673 - val_loss: 1.8306 - val_accuracy: 0.3450\n",
      "Epoch 73/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.8007 - accuracy: 0.3628 - val_loss: 1.8662 - val_accuracy: 0.3255\n",
      "Epoch 74/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7979 - accuracy: 0.3659 - val_loss: 1.9583 - val_accuracy: 0.2795\n",
      "Epoch 75/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7977 - accuracy: 0.3653 - val_loss: 1.8543 - val_accuracy: 0.3390\n",
      "Epoch 76/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7930 - accuracy: 0.3708 - val_loss: 1.8020 - val_accuracy: 0.3680\n",
      "Epoch 77/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7883 - accuracy: 0.3731 - val_loss: 1.8107 - val_accuracy: 0.3660\n",
      "Epoch 78/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7868 - accuracy: 0.3698 - val_loss: 1.8423 - val_accuracy: 0.3300\n",
      "Epoch 79/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7835 - accuracy: 0.3749 - val_loss: 1.8084 - val_accuracy: 0.3605\n",
      "Epoch 80/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7805 - accuracy: 0.3724 - val_loss: 1.8080 - val_accuracy: 0.3555\n",
      "Epoch 81/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7780 - accuracy: 0.3724 - val_loss: 1.8537 - val_accuracy: 0.3295\n",
      "Epoch 82/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7757 - accuracy: 0.3743 - val_loss: 1.8339 - val_accuracy: 0.3400\n",
      "Epoch 83/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7725 - accuracy: 0.3768 - val_loss: 1.8241 - val_accuracy: 0.3495\n",
      "Epoch 84/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7684 - accuracy: 0.3785 - val_loss: 1.7984 - val_accuracy: 0.3570\n",
      "Epoch 85/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7666 - accuracy: 0.3783 - val_loss: 1.8104 - val_accuracy: 0.3540\n",
      "Epoch 86/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7658 - accuracy: 0.3793 - val_loss: 1.8196 - val_accuracy: 0.3495\n",
      "Epoch 87/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7606 - accuracy: 0.3766 - val_loss: 1.7795 - val_accuracy: 0.3710\n",
      "Epoch 88/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7600 - accuracy: 0.3796 - val_loss: 1.8809 - val_accuracy: 0.3430\n",
      "Epoch 89/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7585 - accuracy: 0.3799 - val_loss: 1.8122 - val_accuracy: 0.3515\n",
      "Epoch 90/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7530 - accuracy: 0.3797 - val_loss: 1.8062 - val_accuracy: 0.3460\n",
      "Epoch 91/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7504 - accuracy: 0.3847 - val_loss: 1.7694 - val_accuracy: 0.3810\n",
      "Epoch 92/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7489 - accuracy: 0.3865 - val_loss: 1.7635 - val_accuracy: 0.3800\n",
      "Epoch 93/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7463 - accuracy: 0.3888 - val_loss: 1.7775 - val_accuracy: 0.3655\n",
      "Epoch 94/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7439 - accuracy: 0.3891 - val_loss: 1.7950 - val_accuracy: 0.3380\n",
      "Epoch 95/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7424 - accuracy: 0.3851 - val_loss: 1.7495 - val_accuracy: 0.3835\n",
      "Epoch 96/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7386 - accuracy: 0.3892 - val_loss: 1.7750 - val_accuracy: 0.3690\n",
      "Epoch 97/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7341 - accuracy: 0.3893 - val_loss: 1.7884 - val_accuracy: 0.3600\n",
      "Epoch 98/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7323 - accuracy: 0.3903 - val_loss: 1.7527 - val_accuracy: 0.3960\n",
      "Epoch 99/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7297 - accuracy: 0.3943 - val_loss: 1.7508 - val_accuracy: 0.3925\n",
      "Epoch 100/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7300 - accuracy: 0.3895 - val_loss: 1.7622 - val_accuracy: 0.3700\n",
      "Epoch 101/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7254 - accuracy: 0.3917 - val_loss: 1.7622 - val_accuracy: 0.3785\n",
      "Epoch 102/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7236 - accuracy: 0.3891 - val_loss: 1.7647 - val_accuracy: 0.3700\n",
      "Epoch 103/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7222 - accuracy: 0.3971 - val_loss: 1.7721 - val_accuracy: 0.3715\n",
      "Epoch 104/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7199 - accuracy: 0.3961 - val_loss: 1.7763 - val_accuracy: 0.3615\n",
      "Epoch 105/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7152 - accuracy: 0.3936 - val_loss: 1.7491 - val_accuracy: 0.3905\n",
      "Epoch 106/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7140 - accuracy: 0.3980 - val_loss: 1.8160 - val_accuracy: 0.3505\n",
      "Epoch 107/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7098 - accuracy: 0.3972 - val_loss: 1.7922 - val_accuracy: 0.3710\n",
      "Epoch 108/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7078 - accuracy: 0.3993 - val_loss: 1.7727 - val_accuracy: 0.3615\n",
      "Epoch 109/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7089 - accuracy: 0.3980 - val_loss: 1.7623 - val_accuracy: 0.3695\n",
      "Epoch 110/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7059 - accuracy: 0.3996 - val_loss: 1.7475 - val_accuracy: 0.3655\n",
      "Epoch 111/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.7049 - accuracy: 0.3992 - val_loss: 1.7379 - val_accuracy: 0.3805\n",
      "Epoch 112/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6993 - accuracy: 0.3997 - val_loss: 1.7643 - val_accuracy: 0.3675\n",
      "Epoch 113/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6975 - accuracy: 0.4015 - val_loss: 1.7332 - val_accuracy: 0.3830\n",
      "Epoch 114/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6963 - accuracy: 0.4081 - val_loss: 1.7275 - val_accuracy: 0.3825\n",
      "Epoch 115/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6929 - accuracy: 0.4046 - val_loss: 1.7559 - val_accuracy: 0.3800\n",
      "Epoch 116/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6893 - accuracy: 0.4060 - val_loss: 1.7413 - val_accuracy: 0.3905\n",
      "Epoch 117/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6871 - accuracy: 0.4072 - val_loss: 1.7219 - val_accuracy: 0.4060\n",
      "Epoch 118/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.6845 - accuracy: 0.4069 - val_loss: 1.7347 - val_accuracy: 0.3825\n",
      "Epoch 119/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6834 - accuracy: 0.4144 - val_loss: 1.7119 - val_accuracy: 0.4065\n",
      "Epoch 120/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6812 - accuracy: 0.4072 - val_loss: 1.7159 - val_accuracy: 0.3870\n",
      "Epoch 121/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6788 - accuracy: 0.4130 - val_loss: 1.7227 - val_accuracy: 0.4095\n",
      "Epoch 122/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6766 - accuracy: 0.4105 - val_loss: 1.7529 - val_accuracy: 0.3915\n",
      "Epoch 123/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6740 - accuracy: 0.4084 - val_loss: 1.9144 - val_accuracy: 0.3180\n",
      "Epoch 124/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6749 - accuracy: 0.4104 - val_loss: 1.7363 - val_accuracy: 0.3890\n",
      "Epoch 125/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6711 - accuracy: 0.4140 - val_loss: 1.7143 - val_accuracy: 0.3820\n",
      "Epoch 126/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6684 - accuracy: 0.4126 - val_loss: 1.6972 - val_accuracy: 0.3995\n",
      "Epoch 127/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6652 - accuracy: 0.4177 - val_loss: 1.6883 - val_accuracy: 0.4045\n",
      "Epoch 128/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6614 - accuracy: 0.4169 - val_loss: 1.7602 - val_accuracy: 0.3935\n",
      "Epoch 129/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6589 - accuracy: 0.4201 - val_loss: 1.7038 - val_accuracy: 0.3990\n",
      "Epoch 130/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.6586 - accuracy: 0.4178 - val_loss: 1.7866 - val_accuracy: 0.3685\n",
      "Epoch 131/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6592 - accuracy: 0.4222 - val_loss: 1.7829 - val_accuracy: 0.3530\n",
      "Epoch 132/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6561 - accuracy: 0.4219 - val_loss: 1.7776 - val_accuracy: 0.3800\n",
      "Epoch 133/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.6539 - accuracy: 0.4182 - val_loss: 1.6844 - val_accuracy: 0.4125\n",
      "Epoch 134/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6520 - accuracy: 0.4197 - val_loss: 1.7375 - val_accuracy: 0.3790\n",
      "Epoch 135/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6489 - accuracy: 0.4223 - val_loss: 1.6911 - val_accuracy: 0.4065\n",
      "Epoch 136/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6470 - accuracy: 0.4246 - val_loss: 1.6864 - val_accuracy: 0.4120\n",
      "Epoch 137/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.6469 - accuracy: 0.4189 - val_loss: 1.6877 - val_accuracy: 0.3865\n",
      "Epoch 138/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6456 - accuracy: 0.4221 - val_loss: 1.6930 - val_accuracy: 0.4235\n",
      "Epoch 139/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.6430 - accuracy: 0.4225 - val_loss: 1.7388 - val_accuracy: 0.3950\n",
      "Epoch 140/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6418 - accuracy: 0.4226 - val_loss: 1.6788 - val_accuracy: 0.4125\n",
      "Epoch 141/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6374 - accuracy: 0.4254 - val_loss: 1.6766 - val_accuracy: 0.4200\n",
      "Epoch 142/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6369 - accuracy: 0.4258 - val_loss: 1.7322 - val_accuracy: 0.3845\n",
      "Epoch 143/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6338 - accuracy: 0.4264 - val_loss: 1.6779 - val_accuracy: 0.4080\n",
      "Epoch 144/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6339 - accuracy: 0.4282 - val_loss: 1.7963 - val_accuracy: 0.3730\n",
      "Epoch 145/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6329 - accuracy: 0.4319 - val_loss: 1.7095 - val_accuracy: 0.3995\n",
      "Epoch 146/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6286 - accuracy: 0.4269 - val_loss: 1.7029 - val_accuracy: 0.3870\n",
      "Epoch 147/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6302 - accuracy: 0.4283 - val_loss: 1.7317 - val_accuracy: 0.3775\n",
      "Epoch 148/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6272 - accuracy: 0.4280 - val_loss: 1.7096 - val_accuracy: 0.3940\n",
      "Epoch 149/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6250 - accuracy: 0.4310 - val_loss: 1.7223 - val_accuracy: 0.3990\n",
      "Epoch 150/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6252 - accuracy: 0.4286 - val_loss: 1.6678 - val_accuracy: 0.4070\n",
      "Epoch 151/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6225 - accuracy: 0.4310 - val_loss: 1.7286 - val_accuracy: 0.4010\n",
      "Epoch 152/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6217 - accuracy: 0.4299 - val_loss: 1.6708 - val_accuracy: 0.4130\n",
      "Epoch 153/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6153 - accuracy: 0.4345 - val_loss: 1.7224 - val_accuracy: 0.3960\n",
      "Epoch 154/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6170 - accuracy: 0.4350 - val_loss: 1.7022 - val_accuracy: 0.4150\n",
      "Epoch 155/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6122 - accuracy: 0.4323 - val_loss: 1.6451 - val_accuracy: 0.4165\n",
      "Epoch 156/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6123 - accuracy: 0.4352 - val_loss: 1.6783 - val_accuracy: 0.4115\n",
      "Epoch 157/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6097 - accuracy: 0.4327 - val_loss: 1.6660 - val_accuracy: 0.4285\n",
      "Epoch 158/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6110 - accuracy: 0.4363 - val_loss: 1.6362 - val_accuracy: 0.4360\n",
      "Epoch 159/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6060 - accuracy: 0.4363 - val_loss: 1.7213 - val_accuracy: 0.4000\n",
      "Epoch 160/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6059 - accuracy: 0.4323 - val_loss: 1.7347 - val_accuracy: 0.3965\n",
      "Epoch 161/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6088 - accuracy: 0.4367 - val_loss: 1.6836 - val_accuracy: 0.4015\n",
      "Epoch 162/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6004 - accuracy: 0.4388 - val_loss: 1.6897 - val_accuracy: 0.4200\n",
      "Epoch 163/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5993 - accuracy: 0.4395 - val_loss: 1.6705 - val_accuracy: 0.4225\n",
      "Epoch 164/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6022 - accuracy: 0.4370 - val_loss: 1.7718 - val_accuracy: 0.3655\n",
      "Epoch 165/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5977 - accuracy: 0.4378 - val_loss: 1.6644 - val_accuracy: 0.4150\n",
      "Epoch 166/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5931 - accuracy: 0.4400 - val_loss: 1.6738 - val_accuracy: 0.4065\n",
      "Epoch 167/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5944 - accuracy: 0.4391 - val_loss: 1.6605 - val_accuracy: 0.4200\n",
      "Epoch 168/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5912 - accuracy: 0.4419 - val_loss: 1.7112 - val_accuracy: 0.3915\n",
      "Epoch 169/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5878 - accuracy: 0.4420 - val_loss: 1.6779 - val_accuracy: 0.4070\n",
      "Epoch 170/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5890 - accuracy: 0.4451 - val_loss: 1.6703 - val_accuracy: 0.4220\n",
      "Epoch 171/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5861 - accuracy: 0.4450 - val_loss: 1.6321 - val_accuracy: 0.4350\n",
      "Epoch 172/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5831 - accuracy: 0.4489 - val_loss: 1.6493 - val_accuracy: 0.4230\n",
      "Epoch 173/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5828 - accuracy: 0.4486 - val_loss: 1.6743 - val_accuracy: 0.3975\n",
      "Epoch 174/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5820 - accuracy: 0.4446 - val_loss: 1.6214 - val_accuracy: 0.4435\n",
      "Epoch 175/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5813 - accuracy: 0.4458 - val_loss: 1.7594 - val_accuracy: 0.3840\n",
      "Epoch 176/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5827 - accuracy: 0.4448 - val_loss: 1.6438 - val_accuracy: 0.4340\n",
      "Epoch 177/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5756 - accuracy: 0.4432 - val_loss: 1.6605 - val_accuracy: 0.4185\n",
      "Epoch 178/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5758 - accuracy: 0.4474 - val_loss: 1.6553 - val_accuracy: 0.4085\n",
      "Epoch 179/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5775 - accuracy: 0.4472 - val_loss: 1.8132 - val_accuracy: 0.3555\n",
      "Epoch 180/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5733 - accuracy: 0.4454 - val_loss: 1.6540 - val_accuracy: 0.4170\n",
      "Epoch 181/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5693 - accuracy: 0.4498 - val_loss: 1.6331 - val_accuracy: 0.4295\n",
      "Epoch 182/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5693 - accuracy: 0.4499 - val_loss: 1.7285 - val_accuracy: 0.3725\n",
      "Epoch 183/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5681 - accuracy: 0.4494 - val_loss: 1.7570 - val_accuracy: 0.3715\n",
      "Epoch 184/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5692 - accuracy: 0.4482 - val_loss: 1.6368 - val_accuracy: 0.4190\n",
      "Epoch 185/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5630 - accuracy: 0.4508 - val_loss: 1.6334 - val_accuracy: 0.4480\n",
      "Epoch 186/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5640 - accuracy: 0.4537 - val_loss: 1.9847 - val_accuracy: 0.3055\n",
      "Epoch 187/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5671 - accuracy: 0.4512 - val_loss: 1.6762 - val_accuracy: 0.4090\n",
      "Epoch 188/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5613 - accuracy: 0.4562 - val_loss: 1.7236 - val_accuracy: 0.3985\n",
      "Epoch 189/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5616 - accuracy: 0.4537 - val_loss: 1.8684 - val_accuracy: 0.3695\n",
      "Epoch 190/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5568 - accuracy: 0.4511 - val_loss: 1.6486 - val_accuracy: 0.4255\n",
      "Epoch 191/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5576 - accuracy: 0.4546 - val_loss: 1.8303 - val_accuracy: 0.3580\n",
      "Epoch 192/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5551 - accuracy: 0.4570 - val_loss: 1.6282 - val_accuracy: 0.4240\n",
      "Epoch 193/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5512 - accuracy: 0.4570 - val_loss: 1.7243 - val_accuracy: 0.3890\n",
      "Epoch 194/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5509 - accuracy: 0.4557 - val_loss: 1.8452 - val_accuracy: 0.3545\n",
      "Epoch 195/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5487 - accuracy: 0.4568 - val_loss: 1.6523 - val_accuracy: 0.4030\n",
      "Epoch 196/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5483 - accuracy: 0.4569 - val_loss: 1.6607 - val_accuracy: 0.4000\n",
      "Epoch 197/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5437 - accuracy: 0.4593 - val_loss: 1.6156 - val_accuracy: 0.4230\n",
      "Epoch 198/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5435 - accuracy: 0.4604 - val_loss: 1.6230 - val_accuracy: 0.4430\n",
      "Epoch 199/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5406 - accuracy: 0.4599 - val_loss: 1.6987 - val_accuracy: 0.4035\n",
      "Epoch 200/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5408 - accuracy: 0.4625 - val_loss: 1.6075 - val_accuracy: 0.4435\n",
      "Epoch 201/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5364 - accuracy: 0.4653 - val_loss: 1.5909 - val_accuracy: 0.4455\n",
      "Epoch 202/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5369 - accuracy: 0.4652 - val_loss: 1.7234 - val_accuracy: 0.3860\n",
      "Epoch 203/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5381 - accuracy: 0.4627 - val_loss: 1.5981 - val_accuracy: 0.4470\n",
      "Epoch 204/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5320 - accuracy: 0.4660 - val_loss: 1.6980 - val_accuracy: 0.4180\n",
      "Epoch 205/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5350 - accuracy: 0.4660 - val_loss: 1.7021 - val_accuracy: 0.4050\n",
      "Epoch 206/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5332 - accuracy: 0.4642 - val_loss: 1.6485 - val_accuracy: 0.4145\n",
      "Epoch 207/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5334 - accuracy: 0.4645 - val_loss: 1.6394 - val_accuracy: 0.4335\n",
      "Epoch 208/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5264 - accuracy: 0.4641 - val_loss: 1.5992 - val_accuracy: 0.4435\n",
      "Epoch 209/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5277 - accuracy: 0.4648 - val_loss: 1.6344 - val_accuracy: 0.4355\n",
      "Epoch 210/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5234 - accuracy: 0.4660 - val_loss: 1.6429 - val_accuracy: 0.4295\n",
      "Epoch 211/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5269 - accuracy: 0.4703 - val_loss: 1.6560 - val_accuracy: 0.4160\n",
      "Epoch 212/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5193 - accuracy: 0.4696 - val_loss: 1.5883 - val_accuracy: 0.4555\n",
      "Epoch 213/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5183 - accuracy: 0.4757 - val_loss: 1.6335 - val_accuracy: 0.4230\n",
      "Epoch 214/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5184 - accuracy: 0.4737 - val_loss: 1.6317 - val_accuracy: 0.4285\n",
      "Epoch 215/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5194 - accuracy: 0.4690 - val_loss: 1.6747 - val_accuracy: 0.4140\n",
      "Epoch 216/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5158 - accuracy: 0.4746 - val_loss: 1.6258 - val_accuracy: 0.4330\n",
      "Epoch 217/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5175 - accuracy: 0.4716 - val_loss: 1.6295 - val_accuracy: 0.4355\n",
      "Epoch 218/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5151 - accuracy: 0.4726 - val_loss: 1.6031 - val_accuracy: 0.4540\n",
      "Epoch 219/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5101 - accuracy: 0.4701 - val_loss: 1.6489 - val_accuracy: 0.4325\n",
      "Epoch 220/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5135 - accuracy: 0.4744 - val_loss: 1.5986 - val_accuracy: 0.4455\n",
      "Epoch 221/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5096 - accuracy: 0.4737 - val_loss: 1.7206 - val_accuracy: 0.4085\n",
      "Epoch 222/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5125 - accuracy: 0.4735 - val_loss: 1.5966 - val_accuracy: 0.4290\n",
      "Epoch 223/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5097 - accuracy: 0.4723 - val_loss: 1.6123 - val_accuracy: 0.4300\n",
      "Epoch 224/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5058 - accuracy: 0.4725 - val_loss: 1.5903 - val_accuracy: 0.4475\n",
      "Epoch 225/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5005 - accuracy: 0.4755 - val_loss: 1.5895 - val_accuracy: 0.4420\n",
      "Epoch 226/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4997 - accuracy: 0.4762 - val_loss: 1.5613 - val_accuracy: 0.4675\n",
      "Epoch 227/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4982 - accuracy: 0.4772 - val_loss: 1.5705 - val_accuracy: 0.4505\n",
      "Epoch 228/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5001 - accuracy: 0.4756 - val_loss: 1.8160 - val_accuracy: 0.3710\n",
      "Epoch 229/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5016 - accuracy: 0.4784 - val_loss: 2.0928 - val_accuracy: 0.3300\n",
      "Epoch 230/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.5008 - accuracy: 0.4772 - val_loss: 1.5690 - val_accuracy: 0.4695\n",
      "Epoch 231/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4933 - accuracy: 0.4830 - val_loss: 1.6313 - val_accuracy: 0.4235\n",
      "Epoch 232/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4929 - accuracy: 0.4778 - val_loss: 1.6043 - val_accuracy: 0.4315\n",
      "Epoch 233/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4897 - accuracy: 0.4834 - val_loss: 1.7150 - val_accuracy: 0.4060\n",
      "Epoch 234/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4901 - accuracy: 0.4848 - val_loss: 1.6743 - val_accuracy: 0.4325\n",
      "Epoch 235/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4907 - accuracy: 0.4802 - val_loss: 1.8170 - val_accuracy: 0.3700\n",
      "Epoch 236/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4938 - accuracy: 0.4814 - val_loss: 1.5778 - val_accuracy: 0.4405\n",
      "Epoch 237/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4842 - accuracy: 0.4848 - val_loss: 1.6277 - val_accuracy: 0.4465\n",
      "Epoch 238/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4850 - accuracy: 0.4855 - val_loss: 1.6597 - val_accuracy: 0.4175\n",
      "Epoch 239/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4836 - accuracy: 0.4835 - val_loss: 1.5484 - val_accuracy: 0.4690\n",
      "Epoch 240/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4789 - accuracy: 0.4844 - val_loss: 1.9919 - val_accuracy: 0.3310\n",
      "Epoch 241/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4847 - accuracy: 0.4852 - val_loss: 1.5777 - val_accuracy: 0.4295\n",
      "Epoch 242/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4802 - accuracy: 0.4827 - val_loss: 1.6635 - val_accuracy: 0.4125\n",
      "Epoch 243/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4775 - accuracy: 0.4872 - val_loss: 1.5467 - val_accuracy: 0.4725\n",
      "Epoch 244/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4773 - accuracy: 0.4890 - val_loss: 1.6917 - val_accuracy: 0.4450\n",
      "Epoch 245/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4773 - accuracy: 0.4877 - val_loss: 1.6667 - val_accuracy: 0.4165\n",
      "Epoch 246/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4777 - accuracy: 0.4866 - val_loss: 1.5381 - val_accuracy: 0.4765\n",
      "Epoch 247/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4733 - accuracy: 0.4907 - val_loss: 1.6063 - val_accuracy: 0.4280\n",
      "Epoch 248/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4743 - accuracy: 0.4837 - val_loss: 1.6404 - val_accuracy: 0.4225\n",
      "Epoch 249/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4723 - accuracy: 0.4886 - val_loss: 1.7166 - val_accuracy: 0.4100\n",
      "Epoch 250/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4719 - accuracy: 0.4909 - val_loss: 1.7483 - val_accuracy: 0.3950\n",
      "Epoch 251/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4697 - accuracy: 0.4927 - val_loss: 1.7046 - val_accuracy: 0.4025\n",
      "Epoch 252/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4674 - accuracy: 0.4909 - val_loss: 1.5979 - val_accuracy: 0.4340\n",
      "Epoch 253/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4599 - accuracy: 0.4938 - val_loss: 1.5764 - val_accuracy: 0.4470\n",
      "Epoch 254/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4622 - accuracy: 0.4935 - val_loss: 1.5825 - val_accuracy: 0.4520\n",
      "Epoch 255/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4612 - accuracy: 0.4930 - val_loss: 1.5518 - val_accuracy: 0.4570\n",
      "Epoch 256/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4624 - accuracy: 0.4918 - val_loss: 1.6025 - val_accuracy: 0.4440\n",
      "Epoch 257/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4573 - accuracy: 0.4929 - val_loss: 1.6282 - val_accuracy: 0.4325\n",
      "Epoch 258/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4584 - accuracy: 0.4943 - val_loss: 1.5763 - val_accuracy: 0.4625\n",
      "Epoch 259/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4557 - accuracy: 0.4922 - val_loss: 1.7949 - val_accuracy: 0.3875\n",
      "Epoch 260/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4577 - accuracy: 0.4951 - val_loss: 1.5504 - val_accuracy: 0.4545\n",
      "Epoch 261/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4550 - accuracy: 0.4947 - val_loss: 1.6050 - val_accuracy: 0.4310\n",
      "Epoch 262/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4526 - accuracy: 0.4936 - val_loss: 1.5194 - val_accuracy: 0.4770\n",
      "Epoch 263/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4520 - accuracy: 0.4963 - val_loss: 1.6966 - val_accuracy: 0.4080\n",
      "Epoch 264/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4495 - accuracy: 0.4994 - val_loss: 1.7244 - val_accuracy: 0.3930\n",
      "Epoch 265/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4488 - accuracy: 0.4994 - val_loss: 1.5728 - val_accuracy: 0.4660\n",
      "Epoch 266/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4461 - accuracy: 0.4997 - val_loss: 1.5376 - val_accuracy: 0.4800\n",
      "Epoch 267/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4429 - accuracy: 0.5001 - val_loss: 1.5621 - val_accuracy: 0.4625\n",
      "Epoch 268/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4445 - accuracy: 0.4986 - val_loss: 1.5873 - val_accuracy: 0.4635\n",
      "Epoch 269/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4411 - accuracy: 0.5013 - val_loss: 1.5770 - val_accuracy: 0.4450\n",
      "Epoch 270/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4407 - accuracy: 0.5004 - val_loss: 1.6075 - val_accuracy: 0.4335\n",
      "Epoch 271/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4411 - accuracy: 0.4965 - val_loss: 1.5758 - val_accuracy: 0.4560\n",
      "Epoch 272/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4395 - accuracy: 0.5019 - val_loss: 1.5329 - val_accuracy: 0.4835\n",
      "Epoch 273/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4379 - accuracy: 0.5030 - val_loss: 1.5395 - val_accuracy: 0.4675\n",
      "Epoch 274/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4353 - accuracy: 0.5019 - val_loss: 1.5917 - val_accuracy: 0.4390\n",
      "Epoch 275/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4334 - accuracy: 0.5075 - val_loss: 1.6210 - val_accuracy: 0.4495\n",
      "Epoch 276/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4322 - accuracy: 0.5024 - val_loss: 1.6117 - val_accuracy: 0.4315\n",
      "Epoch 277/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4297 - accuracy: 0.5036 - val_loss: 1.8468 - val_accuracy: 0.3460\n",
      "Epoch 278/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4352 - accuracy: 0.5018 - val_loss: 1.5521 - val_accuracy: 0.4545\n",
      "Epoch 279/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4279 - accuracy: 0.5106 - val_loss: 1.5703 - val_accuracy: 0.4520\n",
      "Epoch 280/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4249 - accuracy: 0.5059 - val_loss: 1.7512 - val_accuracy: 0.3845\n",
      "Epoch 281/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4238 - accuracy: 0.5100 - val_loss: 1.6916 - val_accuracy: 0.4005\n",
      "Epoch 282/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4267 - accuracy: 0.5049 - val_loss: 1.6526 - val_accuracy: 0.4260\n",
      "Epoch 283/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4230 - accuracy: 0.5061 - val_loss: 1.6808 - val_accuracy: 0.4080\n",
      "Epoch 284/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4225 - accuracy: 0.5082 - val_loss: 1.6006 - val_accuracy: 0.4430\n",
      "Epoch 285/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4218 - accuracy: 0.5056 - val_loss: 1.6792 - val_accuracy: 0.3990\n",
      "Epoch 286/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4225 - accuracy: 0.5090 - val_loss: 1.5097 - val_accuracy: 0.4795\n",
      "Epoch 287/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4148 - accuracy: 0.5088 - val_loss: 1.6514 - val_accuracy: 0.4250\n",
      "Epoch 288/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4211 - accuracy: 0.5109 - val_loss: 1.5300 - val_accuracy: 0.4665\n",
      "Epoch 289/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4131 - accuracy: 0.5094 - val_loss: 1.5293 - val_accuracy: 0.4635\n",
      "Epoch 290/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4134 - accuracy: 0.5095 - val_loss: 1.5052 - val_accuracy: 0.4825\n",
      "Epoch 291/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4111 - accuracy: 0.5090 - val_loss: 1.6507 - val_accuracy: 0.4360\n",
      "Epoch 292/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4103 - accuracy: 0.5103 - val_loss: 1.5181 - val_accuracy: 0.4820\n",
      "Epoch 293/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4095 - accuracy: 0.5121 - val_loss: 1.5306 - val_accuracy: 0.4790\n",
      "Epoch 294/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4127 - accuracy: 0.5143 - val_loss: 1.5670 - val_accuracy: 0.4530\n",
      "Epoch 295/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4085 - accuracy: 0.5141 - val_loss: 1.5695 - val_accuracy: 0.4515\n",
      "Epoch 296/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4067 - accuracy: 0.5136 - val_loss: 1.6526 - val_accuracy: 0.4275\n",
      "Epoch 297/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4118 - accuracy: 0.5091 - val_loss: 1.5991 - val_accuracy: 0.4320\n",
      "Epoch 298/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4003 - accuracy: 0.5141 - val_loss: 1.5291 - val_accuracy: 0.4710\n",
      "Epoch 299/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4013 - accuracy: 0.5152 - val_loss: 1.6076 - val_accuracy: 0.4355\n",
      "Epoch 300/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.4040 - accuracy: 0.5185 - val_loss: 1.7350 - val_accuracy: 0.4020\n",
      "Epoch 301/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4015 - accuracy: 0.5164 - val_loss: 1.6256 - val_accuracy: 0.4365\n",
      "Epoch 302/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.4013 - accuracy: 0.5162 - val_loss: 1.4876 - val_accuracy: 0.5030\n",
      "Epoch 303/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.3984 - accuracy: 0.5147 - val_loss: 1.5169 - val_accuracy: 0.4775\n",
      "Epoch 304/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3973 - accuracy: 0.5139 - val_loss: 1.5314 - val_accuracy: 0.4630\n",
      "Epoch 305/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3952 - accuracy: 0.5156 - val_loss: 1.4997 - val_accuracy: 0.4775\n",
      "Epoch 306/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3923 - accuracy: 0.5157 - val_loss: 1.5402 - val_accuracy: 0.4640\n",
      "Epoch 307/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3897 - accuracy: 0.5203 - val_loss: 1.7684 - val_accuracy: 0.4005\n",
      "Epoch 308/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3969 - accuracy: 0.5173 - val_loss: 1.5639 - val_accuracy: 0.4520\n",
      "Epoch 309/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3922 - accuracy: 0.5162 - val_loss: 1.6631 - val_accuracy: 0.4245\n",
      "Epoch 310/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3899 - accuracy: 0.5220 - val_loss: 1.5435 - val_accuracy: 0.4670\n",
      "Epoch 311/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3892 - accuracy: 0.5198 - val_loss: 1.5988 - val_accuracy: 0.4425\n",
      "Epoch 312/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3892 - accuracy: 0.5204 - val_loss: 1.5391 - val_accuracy: 0.4715\n",
      "Epoch 313/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3855 - accuracy: 0.5203 - val_loss: 1.6250 - val_accuracy: 0.4510\n",
      "Epoch 314/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3867 - accuracy: 0.5219 - val_loss: 1.5614 - val_accuracy: 0.4535\n",
      "Epoch 315/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3842 - accuracy: 0.5251 - val_loss: 1.6554 - val_accuracy: 0.4350\n",
      "Epoch 316/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3834 - accuracy: 0.5203 - val_loss: 1.5584 - val_accuracy: 0.4525\n",
      "Epoch 317/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3830 - accuracy: 0.5227 - val_loss: 1.5810 - val_accuracy: 0.4390\n",
      "Epoch 318/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3793 - accuracy: 0.5258 - val_loss: 1.8397 - val_accuracy: 0.3685\n",
      "Epoch 319/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3856 - accuracy: 0.5204 - val_loss: 1.4867 - val_accuracy: 0.4915\n",
      "Epoch 320/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3737 - accuracy: 0.5273 - val_loss: 1.5460 - val_accuracy: 0.4865\n",
      "Epoch 321/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.3787 - accuracy: 0.5256 - val_loss: 1.4938 - val_accuracy: 0.4890\n",
      "Epoch 322/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3745 - accuracy: 0.5258 - val_loss: 1.5855 - val_accuracy: 0.4440\n",
      "Epoch 323/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3749 - accuracy: 0.5279 - val_loss: 1.6085 - val_accuracy: 0.4365\n",
      "Epoch 324/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3733 - accuracy: 0.5268 - val_loss: 1.5344 - val_accuracy: 0.4630\n",
      "Epoch 325/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3744 - accuracy: 0.5273 - val_loss: 1.5024 - val_accuracy: 0.4810\n",
      "Epoch 326/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3695 - accuracy: 0.5290 - val_loss: 1.6801 - val_accuracy: 0.4335\n",
      "Epoch 327/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3711 - accuracy: 0.5275 - val_loss: 1.5733 - val_accuracy: 0.4400\n",
      "Epoch 328/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3702 - accuracy: 0.5273 - val_loss: 1.7297 - val_accuracy: 0.4025\n",
      "Epoch 329/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.3666 - accuracy: 0.5263 - val_loss: 1.6371 - val_accuracy: 0.4340\n",
      "Epoch 330/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3671 - accuracy: 0.5298 - val_loss: 1.4955 - val_accuracy: 0.4735\n",
      "Epoch 331/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3681 - accuracy: 0.5286 - val_loss: 1.5590 - val_accuracy: 0.4605\n",
      "Epoch 332/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3624 - accuracy: 0.5339 - val_loss: 1.4984 - val_accuracy: 0.4835\n",
      "Epoch 333/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3614 - accuracy: 0.5290 - val_loss: 1.5695 - val_accuracy: 0.4565\n",
      "Epoch 334/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3611 - accuracy: 0.5268 - val_loss: 1.5487 - val_accuracy: 0.4645\n",
      "Epoch 335/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3619 - accuracy: 0.5294 - val_loss: 1.5574 - val_accuracy: 0.4465\n",
      "Epoch 336/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3577 - accuracy: 0.5296 - val_loss: 1.5231 - val_accuracy: 0.4610\n",
      "Epoch 337/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3627 - accuracy: 0.5309 - val_loss: 1.4946 - val_accuracy: 0.4805\n",
      "Epoch 338/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3530 - accuracy: 0.5330 - val_loss: 1.6627 - val_accuracy: 0.4180\n",
      "Epoch 339/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3524 - accuracy: 0.5298 - val_loss: 1.6317 - val_accuracy: 0.4395\n",
      "Epoch 340/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3551 - accuracy: 0.5314 - val_loss: 1.7016 - val_accuracy: 0.4205\n",
      "Epoch 341/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3505 - accuracy: 0.5370 - val_loss: 1.6056 - val_accuracy: 0.4405\n",
      "Epoch 342/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3517 - accuracy: 0.5332 - val_loss: 1.6170 - val_accuracy: 0.4255\n",
      "Epoch 343/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3475 - accuracy: 0.5346 - val_loss: 1.5070 - val_accuracy: 0.4815\n",
      "Epoch 344/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3474 - accuracy: 0.5293 - val_loss: 1.8117 - val_accuracy: 0.3785\n",
      "Epoch 345/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3564 - accuracy: 0.5349 - val_loss: 1.4711 - val_accuracy: 0.5045\n",
      "Epoch 346/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3465 - accuracy: 0.5344 - val_loss: 1.5151 - val_accuracy: 0.4710\n",
      "Epoch 347/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3422 - accuracy: 0.5364 - val_loss: 1.4870 - val_accuracy: 0.4820\n",
      "Epoch 348/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3408 - accuracy: 0.5404 - val_loss: 1.6421 - val_accuracy: 0.4260\n",
      "Epoch 349/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3437 - accuracy: 0.5360 - val_loss: 1.6433 - val_accuracy: 0.4290\n",
      "Epoch 350/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3421 - accuracy: 0.5349 - val_loss: 1.7305 - val_accuracy: 0.4405\n",
      "Epoch 351/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3458 - accuracy: 0.5389 - val_loss: 1.4722 - val_accuracy: 0.4885\n",
      "Epoch 352/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3366 - accuracy: 0.5395 - val_loss: 1.4671 - val_accuracy: 0.5010\n",
      "Epoch 353/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3363 - accuracy: 0.5414 - val_loss: 1.4876 - val_accuracy: 0.4870\n",
      "Epoch 354/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3340 - accuracy: 0.5411 - val_loss: 1.6941 - val_accuracy: 0.4130\n",
      "Epoch 355/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3399 - accuracy: 0.5391 - val_loss: 1.5332 - val_accuracy: 0.4610\n",
      "Epoch 356/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3327 - accuracy: 0.5354 - val_loss: 1.4883 - val_accuracy: 0.4875\n",
      "Epoch 357/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3335 - accuracy: 0.5373 - val_loss: 1.4979 - val_accuracy: 0.4785\n",
      "Epoch 358/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3327 - accuracy: 0.5417 - val_loss: 1.5678 - val_accuracy: 0.4590\n",
      "Epoch 359/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3386 - accuracy: 0.5331 - val_loss: 1.5497 - val_accuracy: 0.4490\n",
      "Epoch 360/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3308 - accuracy: 0.5423 - val_loss: 1.5003 - val_accuracy: 0.4790\n",
      "Epoch 361/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3315 - accuracy: 0.5412 - val_loss: 1.5080 - val_accuracy: 0.4790\n",
      "Epoch 362/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3308 - accuracy: 0.5411 - val_loss: 1.5182 - val_accuracy: 0.4760\n",
      "Epoch 363/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3312 - accuracy: 0.5403 - val_loss: 1.5007 - val_accuracy: 0.4935\n",
      "Epoch 364/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3240 - accuracy: 0.5369 - val_loss: 1.7329 - val_accuracy: 0.4085\n",
      "Epoch 365/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3265 - accuracy: 0.5436 - val_loss: 1.4774 - val_accuracy: 0.4865\n",
      "Epoch 366/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3265 - accuracy: 0.5438 - val_loss: 1.5032 - val_accuracy: 0.4825\n",
      "Epoch 367/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3197 - accuracy: 0.5455 - val_loss: 1.6313 - val_accuracy: 0.4155\n",
      "Epoch 368/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3202 - accuracy: 0.5470 - val_loss: 1.5020 - val_accuracy: 0.4810\n",
      "Epoch 369/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3187 - accuracy: 0.5448 - val_loss: 1.4624 - val_accuracy: 0.5090\n",
      "Epoch 370/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3177 - accuracy: 0.5491 - val_loss: 1.5008 - val_accuracy: 0.4725\n",
      "Epoch 371/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3179 - accuracy: 0.5454 - val_loss: 1.5777 - val_accuracy: 0.4515\n",
      "Epoch 372/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3171 - accuracy: 0.5464 - val_loss: 1.5590 - val_accuracy: 0.4590\n",
      "Epoch 373/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3211 - accuracy: 0.5448 - val_loss: 1.5959 - val_accuracy: 0.4730\n",
      "Epoch 374/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.3134 - accuracy: 0.5481 - val_loss: 2.0889 - val_accuracy: 0.3605\n",
      "Epoch 375/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3218 - accuracy: 0.5461 - val_loss: 1.5200 - val_accuracy: 0.4785\n",
      "Epoch 376/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3133 - accuracy: 0.5473 - val_loss: 1.4565 - val_accuracy: 0.5010\n",
      "Epoch 377/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3108 - accuracy: 0.5486 - val_loss: 1.5246 - val_accuracy: 0.4650\n",
      "Epoch 378/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3094 - accuracy: 0.5499 - val_loss: 1.5424 - val_accuracy: 0.4590\n",
      "Epoch 379/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3092 - accuracy: 0.5464 - val_loss: 1.5320 - val_accuracy: 0.4705\n",
      "Epoch 380/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3083 - accuracy: 0.5512 - val_loss: 1.4679 - val_accuracy: 0.4965\n",
      "Epoch 381/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3068 - accuracy: 0.5511 - val_loss: 1.4823 - val_accuracy: 0.4845\n",
      "Epoch 382/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3035 - accuracy: 0.5490 - val_loss: 1.5331 - val_accuracy: 0.4680\n",
      "Epoch 383/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3064 - accuracy: 0.5488 - val_loss: 1.7362 - val_accuracy: 0.4275\n",
      "Epoch 384/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3016 - accuracy: 0.5533 - val_loss: 1.6348 - val_accuracy: 0.4235\n",
      "Epoch 385/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3038 - accuracy: 0.5518 - val_loss: 1.5589 - val_accuracy: 0.4545\n",
      "Epoch 386/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.3021 - accuracy: 0.5515 - val_loss: 1.5052 - val_accuracy: 0.4765\n",
      "Epoch 387/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2952 - accuracy: 0.5515 - val_loss: 1.4606 - val_accuracy: 0.5100\n",
      "Epoch 388/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2965 - accuracy: 0.5548 - val_loss: 1.4910 - val_accuracy: 0.4745\n",
      "Epoch 389/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2952 - accuracy: 0.5531 - val_loss: 1.4740 - val_accuracy: 0.4845\n",
      "Epoch 390/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2944 - accuracy: 0.5532 - val_loss: 1.5717 - val_accuracy: 0.4540\n",
      "Epoch 391/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2969 - accuracy: 0.5520 - val_loss: 1.4905 - val_accuracy: 0.4895\n",
      "Epoch 392/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2934 - accuracy: 0.5573 - val_loss: 1.5101 - val_accuracy: 0.4805\n",
      "Epoch 393/1000\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.2926 - accuracy: 0.5591 - val_loss: 1.5357 - val_accuracy: 0.4875\n",
      "Epoch 394/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2969 - accuracy: 0.5492 - val_loss: 1.4645 - val_accuracy: 0.4990\n",
      "Epoch 395/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2891 - accuracy: 0.5551 - val_loss: 1.4570 - val_accuracy: 0.4960\n",
      "Epoch 396/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2915 - accuracy: 0.5553 - val_loss: 1.7097 - val_accuracy: 0.4510\n",
      "Epoch 397/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2902 - accuracy: 0.5561 - val_loss: 1.5497 - val_accuracy: 0.4765\n",
      "Epoch 398/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2930 - accuracy: 0.5569 - val_loss: 1.6618 - val_accuracy: 0.4250\n",
      "Epoch 399/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2894 - accuracy: 0.5504 - val_loss: 1.5716 - val_accuracy: 0.4520\n",
      "Epoch 400/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2868 - accuracy: 0.5566 - val_loss: 1.4524 - val_accuracy: 0.5095\n",
      "Epoch 401/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2852 - accuracy: 0.5611 - val_loss: 1.7336 - val_accuracy: 0.3975\n",
      "Epoch 402/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2815 - accuracy: 0.5533 - val_loss: 1.4990 - val_accuracy: 0.4835\n",
      "Epoch 403/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2881 - accuracy: 0.5522 - val_loss: 1.5455 - val_accuracy: 0.4570\n",
      "Epoch 404/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2861 - accuracy: 0.5580 - val_loss: 1.7484 - val_accuracy: 0.4125\n",
      "Epoch 405/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2786 - accuracy: 0.5610 - val_loss: 1.4819 - val_accuracy: 0.4980\n",
      "Epoch 406/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2746 - accuracy: 0.5597 - val_loss: 1.5132 - val_accuracy: 0.4855\n",
      "Epoch 407/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2795 - accuracy: 0.5582 - val_loss: 1.4791 - val_accuracy: 0.4880\n",
      "Epoch 408/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2760 - accuracy: 0.5605 - val_loss: 1.4491 - val_accuracy: 0.5075\n",
      "Epoch 409/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2795 - accuracy: 0.5636 - val_loss: 1.5164 - val_accuracy: 0.4660\n",
      "Epoch 410/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2746 - accuracy: 0.5569 - val_loss: 1.6077 - val_accuracy: 0.4455\n",
      "Epoch 411/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2772 - accuracy: 0.5595 - val_loss: 1.4538 - val_accuracy: 0.5025\n",
      "Epoch 412/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2683 - accuracy: 0.5629 - val_loss: 1.4471 - val_accuracy: 0.4915\n",
      "Epoch 413/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2708 - accuracy: 0.5625 - val_loss: 1.4482 - val_accuracy: 0.5035\n",
      "Epoch 414/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2705 - accuracy: 0.5591 - val_loss: 1.7431 - val_accuracy: 0.4095\n",
      "Epoch 415/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2745 - accuracy: 0.5585 - val_loss: 1.7032 - val_accuracy: 0.4180\n",
      "Epoch 416/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2700 - accuracy: 0.5624 - val_loss: 1.5481 - val_accuracy: 0.4605\n",
      "Epoch 417/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2678 - accuracy: 0.5585 - val_loss: 1.4966 - val_accuracy: 0.4760\n",
      "Epoch 418/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2630 - accuracy: 0.5637 - val_loss: 1.4779 - val_accuracy: 0.4865\n",
      "Epoch 419/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2618 - accuracy: 0.5618 - val_loss: 1.4768 - val_accuracy: 0.4805\n",
      "Epoch 420/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2649 - accuracy: 0.5628 - val_loss: 1.4435 - val_accuracy: 0.4995\n",
      "Epoch 421/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2550 - accuracy: 0.5663 - val_loss: 1.4743 - val_accuracy: 0.4975\n",
      "Epoch 422/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2568 - accuracy: 0.5662 - val_loss: 1.4448 - val_accuracy: 0.4975\n",
      "Epoch 423/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2573 - accuracy: 0.5646 - val_loss: 1.7217 - val_accuracy: 0.4165\n",
      "Epoch 424/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2636 - accuracy: 0.5623 - val_loss: 1.4304 - val_accuracy: 0.5095\n",
      "Epoch 425/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2659 - accuracy: 0.5609 - val_loss: 1.5527 - val_accuracy: 0.4645\n",
      "Epoch 426/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2576 - accuracy: 0.5656 - val_loss: 1.4507 - val_accuracy: 0.5030\n",
      "Epoch 427/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2531 - accuracy: 0.5669 - val_loss: 1.5994 - val_accuracy: 0.4630\n",
      "Epoch 428/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2536 - accuracy: 0.5654 - val_loss: 1.4455 - val_accuracy: 0.4910\n",
      "Epoch 429/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2542 - accuracy: 0.5665 - val_loss: 1.6677 - val_accuracy: 0.4255\n",
      "Epoch 430/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2553 - accuracy: 0.5662 - val_loss: 1.5330 - val_accuracy: 0.4600\n",
      "Epoch 431/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2568 - accuracy: 0.5660 - val_loss: 1.4183 - val_accuracy: 0.5150\n",
      "Epoch 432/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2517 - accuracy: 0.5681 - val_loss: 1.4971 - val_accuracy: 0.4855\n",
      "Epoch 433/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2479 - accuracy: 0.5705 - val_loss: 1.5476 - val_accuracy: 0.4775\n",
      "Epoch 434/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2513 - accuracy: 0.5642 - val_loss: 1.4324 - val_accuracy: 0.5105\n",
      "Epoch 435/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2495 - accuracy: 0.5684 - val_loss: 1.4466 - val_accuracy: 0.4995\n",
      "Epoch 436/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2502 - accuracy: 0.5689 - val_loss: 1.4624 - val_accuracy: 0.4880\n",
      "Epoch 437/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2426 - accuracy: 0.5716 - val_loss: 1.4344 - val_accuracy: 0.4995\n",
      "Epoch 438/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2403 - accuracy: 0.5742 - val_loss: 1.5368 - val_accuracy: 0.4530\n",
      "Epoch 439/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2465 - accuracy: 0.5683 - val_loss: 1.6705 - val_accuracy: 0.4180\n",
      "Epoch 440/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2476 - accuracy: 0.5704 - val_loss: 1.6074 - val_accuracy: 0.4490\n",
      "Epoch 441/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2415 - accuracy: 0.5710 - val_loss: 1.4603 - val_accuracy: 0.5050\n",
      "Epoch 442/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2388 - accuracy: 0.5759 - val_loss: 1.5730 - val_accuracy: 0.4640\n",
      "Epoch 443/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2403 - accuracy: 0.5701 - val_loss: 1.4507 - val_accuracy: 0.4985\n",
      "Epoch 444/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2372 - accuracy: 0.5731 - val_loss: 1.4226 - val_accuracy: 0.5090\n",
      "Epoch 445/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2379 - accuracy: 0.5736 - val_loss: 1.4514 - val_accuracy: 0.4940\n",
      "Epoch 446/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2320 - accuracy: 0.5726 - val_loss: 1.5306 - val_accuracy: 0.4840\n",
      "Epoch 447/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2336 - accuracy: 0.5767 - val_loss: 1.6633 - val_accuracy: 0.4295\n",
      "Epoch 448/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2372 - accuracy: 0.5721 - val_loss: 1.4876 - val_accuracy: 0.4805\n",
      "Epoch 449/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2339 - accuracy: 0.5762 - val_loss: 1.5696 - val_accuracy: 0.4685\n",
      "Epoch 450/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2304 - accuracy: 0.5775 - val_loss: 1.4341 - val_accuracy: 0.5015\n",
      "Epoch 451/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2309 - accuracy: 0.5753 - val_loss: 1.4767 - val_accuracy: 0.4945\n",
      "Epoch 452/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2314 - accuracy: 0.5748 - val_loss: 1.5586 - val_accuracy: 0.4625\n",
      "Epoch 453/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2319 - accuracy: 0.5766 - val_loss: 1.4972 - val_accuracy: 0.4770\n",
      "Epoch 454/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2302 - accuracy: 0.5790 - val_loss: 1.6925 - val_accuracy: 0.4495\n",
      "Epoch 455/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2342 - accuracy: 0.5751 - val_loss: 1.5481 - val_accuracy: 0.4655\n",
      "Epoch 456/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2261 - accuracy: 0.5768 - val_loss: 1.7721 - val_accuracy: 0.3940\n",
      "Epoch 457/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2276 - accuracy: 0.5751 - val_loss: 1.4980 - val_accuracy: 0.4870\n",
      "Epoch 458/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2228 - accuracy: 0.5758 - val_loss: 1.6496 - val_accuracy: 0.4240\n",
      "Epoch 459/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2193 - accuracy: 0.5794 - val_loss: 1.4560 - val_accuracy: 0.4980\n",
      "Epoch 460/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2169 - accuracy: 0.5788 - val_loss: 1.5695 - val_accuracy: 0.4480\n",
      "Epoch 461/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2265 - accuracy: 0.5803 - val_loss: 1.7331 - val_accuracy: 0.4075\n",
      "Epoch 462/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2197 - accuracy: 0.5825 - val_loss: 1.5315 - val_accuracy: 0.4830\n",
      "Epoch 463/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2149 - accuracy: 0.5794 - val_loss: 1.4361 - val_accuracy: 0.4985\n",
      "Epoch 464/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2134 - accuracy: 0.5795 - val_loss: 1.4556 - val_accuracy: 0.4955\n",
      "Epoch 465/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2152 - accuracy: 0.5753 - val_loss: 1.4831 - val_accuracy: 0.4850\n",
      "Epoch 466/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2156 - accuracy: 0.5789 - val_loss: 1.4869 - val_accuracy: 0.4760\n",
      "Epoch 467/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2191 - accuracy: 0.5779 - val_loss: 1.5693 - val_accuracy: 0.4665\n",
      "Epoch 468/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2116 - accuracy: 0.5789 - val_loss: 1.4367 - val_accuracy: 0.5095\n",
      "Epoch 469/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2208 - accuracy: 0.5784 - val_loss: 1.5559 - val_accuracy: 0.4700\n",
      "Epoch 470/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2120 - accuracy: 0.5787 - val_loss: 1.4617 - val_accuracy: 0.5035\n",
      "Epoch 471/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2120 - accuracy: 0.5848 - val_loss: 1.4522 - val_accuracy: 0.4980\n",
      "Epoch 472/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2094 - accuracy: 0.5780 - val_loss: 1.4463 - val_accuracy: 0.4930\n",
      "Epoch 473/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2034 - accuracy: 0.5865 - val_loss: 1.6032 - val_accuracy: 0.4490\n",
      "Epoch 474/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2048 - accuracy: 0.5842 - val_loss: 1.6037 - val_accuracy: 0.4725\n",
      "Epoch 475/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2084 - accuracy: 0.5823 - val_loss: 1.5158 - val_accuracy: 0.4655\n",
      "Epoch 476/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2020 - accuracy: 0.5864 - val_loss: 1.6103 - val_accuracy: 0.4465\n",
      "Epoch 477/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2044 - accuracy: 0.5833 - val_loss: 1.4793 - val_accuracy: 0.4915\n",
      "Epoch 478/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1997 - accuracy: 0.5854 - val_loss: 1.4303 - val_accuracy: 0.5060\n",
      "Epoch 479/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2051 - accuracy: 0.5868 - val_loss: 1.6768 - val_accuracy: 0.4300\n",
      "Epoch 480/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2029 - accuracy: 0.5855 - val_loss: 1.4309 - val_accuracy: 0.5060\n",
      "Epoch 481/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1969 - accuracy: 0.5872 - val_loss: 1.4296 - val_accuracy: 0.5035\n",
      "Epoch 482/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1996 - accuracy: 0.5864 - val_loss: 1.5799 - val_accuracy: 0.4670\n",
      "Epoch 483/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.2014 - accuracy: 0.5880 - val_loss: 1.5360 - val_accuracy: 0.4675\n",
      "Epoch 484/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1969 - accuracy: 0.5844 - val_loss: 1.4261 - val_accuracy: 0.5085\n",
      "Epoch 485/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1922 - accuracy: 0.5929 - val_loss: 1.5053 - val_accuracy: 0.4760\n",
      "Epoch 486/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1905 - accuracy: 0.5907 - val_loss: 1.4714 - val_accuracy: 0.4860\n",
      "Epoch 487/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1941 - accuracy: 0.5857 - val_loss: 1.4985 - val_accuracy: 0.4915\n",
      "Epoch 488/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1882 - accuracy: 0.5909 - val_loss: 1.4422 - val_accuracy: 0.4980\n",
      "Epoch 489/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1840 - accuracy: 0.5929 - val_loss: 1.4262 - val_accuracy: 0.5055\n",
      "Epoch 490/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1924 - accuracy: 0.5884 - val_loss: 1.4271 - val_accuracy: 0.5030\n",
      "Epoch 491/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1880 - accuracy: 0.5903 - val_loss: 1.6065 - val_accuracy: 0.4380\n",
      "Epoch 492/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1914 - accuracy: 0.5860 - val_loss: 1.5146 - val_accuracy: 0.4610\n",
      "Epoch 493/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1861 - accuracy: 0.5874 - val_loss: 1.5213 - val_accuracy: 0.4745\n",
      "Epoch 494/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1845 - accuracy: 0.5919 - val_loss: 1.5343 - val_accuracy: 0.4700\n",
      "Epoch 495/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1864 - accuracy: 0.5904 - val_loss: 1.4226 - val_accuracy: 0.5090\n",
      "Epoch 496/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1828 - accuracy: 0.5903 - val_loss: 1.4580 - val_accuracy: 0.4995\n",
      "Epoch 497/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1770 - accuracy: 0.5939 - val_loss: 1.5190 - val_accuracy: 0.4615\n",
      "Epoch 498/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1797 - accuracy: 0.5899 - val_loss: 1.4927 - val_accuracy: 0.4945\n",
      "Epoch 499/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1770 - accuracy: 0.5936 - val_loss: 1.4061 - val_accuracy: 0.5195\n",
      "Epoch 500/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1758 - accuracy: 0.5976 - val_loss: 1.4594 - val_accuracy: 0.5005\n",
      "Epoch 501/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1811 - accuracy: 0.5947 - val_loss: 1.6823 - val_accuracy: 0.4315\n",
      "Epoch 502/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1821 - accuracy: 0.5946 - val_loss: 1.4489 - val_accuracy: 0.4885\n",
      "Epoch 503/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1751 - accuracy: 0.5957 - val_loss: 1.5263 - val_accuracy: 0.4665\n",
      "Epoch 504/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1706 - accuracy: 0.5962 - val_loss: 1.4672 - val_accuracy: 0.4910\n",
      "Epoch 505/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1727 - accuracy: 0.5923 - val_loss: 1.4089 - val_accuracy: 0.5090\n",
      "Epoch 506/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1698 - accuracy: 0.5974 - val_loss: 1.4194 - val_accuracy: 0.4980\n",
      "Epoch 507/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1736 - accuracy: 0.5928 - val_loss: 1.5963 - val_accuracy: 0.4525\n",
      "Epoch 508/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1764 - accuracy: 0.5951 - val_loss: 1.4916 - val_accuracy: 0.4805\n",
      "Epoch 509/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1731 - accuracy: 0.5949 - val_loss: 1.4948 - val_accuracy: 0.4840\n",
      "Epoch 510/1000\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 1.1787 - accuracy: 0.5935 - val_loss: 1.4637 - val_accuracy: 0.4905\n",
      "Epoch 511/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1661 - accuracy: 0.5976 - val_loss: 1.5081 - val_accuracy: 0.4660\n",
      "Epoch 512/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1614 - accuracy: 0.6009 - val_loss: 1.5183 - val_accuracy: 0.4850\n",
      "Epoch 513/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1668 - accuracy: 0.5987 - val_loss: 1.4310 - val_accuracy: 0.5035\n",
      "Epoch 514/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1631 - accuracy: 0.5942 - val_loss: 1.4224 - val_accuracy: 0.5090\n",
      "Epoch 515/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1597 - accuracy: 0.5993 - val_loss: 1.4560 - val_accuracy: 0.5020\n",
      "Epoch 516/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1592 - accuracy: 0.5974 - val_loss: 1.4746 - val_accuracy: 0.4865\n",
      "Epoch 517/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1555 - accuracy: 0.5990 - val_loss: 1.9609 - val_accuracy: 0.3505\n",
      "Epoch 518/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1749 - accuracy: 0.5920 - val_loss: 1.4548 - val_accuracy: 0.4955\n",
      "Epoch 519/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1508 - accuracy: 0.6018 - val_loss: 1.5069 - val_accuracy: 0.4785\n",
      "Epoch 520/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1665 - accuracy: 0.5987 - val_loss: 1.4758 - val_accuracy: 0.4905\n",
      "Epoch 521/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1554 - accuracy: 0.5982 - val_loss: 1.5139 - val_accuracy: 0.4765\n",
      "Epoch 522/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1638 - accuracy: 0.5999 - val_loss: 1.4551 - val_accuracy: 0.5050\n",
      "Epoch 523/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1579 - accuracy: 0.5993 - val_loss: 1.4722 - val_accuracy: 0.4790\n",
      "Epoch 524/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1502 - accuracy: 0.6070 - val_loss: 1.4000 - val_accuracy: 0.5215\n",
      "Epoch 525/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1525 - accuracy: 0.6005 - val_loss: 1.4387 - val_accuracy: 0.5055\n",
      "Epoch 526/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1498 - accuracy: 0.6041 - val_loss: 1.4481 - val_accuracy: 0.4955\n",
      "Epoch 527/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1534 - accuracy: 0.6001 - val_loss: 1.4275 - val_accuracy: 0.5030\n",
      "Epoch 528/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1485 - accuracy: 0.6039 - val_loss: 1.5094 - val_accuracy: 0.4985\n",
      "Epoch 529/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1465 - accuracy: 0.6012 - val_loss: 1.4520 - val_accuracy: 0.4880\n",
      "Epoch 530/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1470 - accuracy: 0.6020 - val_loss: 1.4856 - val_accuracy: 0.4865\n",
      "Epoch 531/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1445 - accuracy: 0.6012 - val_loss: 2.3780 - val_accuracy: 0.3400\n",
      "Epoch 532/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1550 - accuracy: 0.6011 - val_loss: 1.4457 - val_accuracy: 0.4930\n",
      "Epoch 533/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1381 - accuracy: 0.6055 - val_loss: 1.5340 - val_accuracy: 0.4600\n",
      "Epoch 534/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1405 - accuracy: 0.6052 - val_loss: 1.5653 - val_accuracy: 0.4575\n",
      "Epoch 535/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1431 - accuracy: 0.6072 - val_loss: 1.4349 - val_accuracy: 0.5050\n",
      "Epoch 536/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1442 - accuracy: 0.6048 - val_loss: 1.5458 - val_accuracy: 0.4625\n",
      "Epoch 537/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1420 - accuracy: 0.6070 - val_loss: 1.4613 - val_accuracy: 0.5000\n",
      "Epoch 538/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1322 - accuracy: 0.6120 - val_loss: 1.4448 - val_accuracy: 0.5130\n",
      "Epoch 539/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1369 - accuracy: 0.6121 - val_loss: 1.5775 - val_accuracy: 0.4670\n",
      "Epoch 540/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1376 - accuracy: 0.6078 - val_loss: 1.4555 - val_accuracy: 0.4890\n",
      "Epoch 541/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1340 - accuracy: 0.6100 - val_loss: 1.4574 - val_accuracy: 0.4900\n",
      "Epoch 542/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1374 - accuracy: 0.6073 - val_loss: 1.4326 - val_accuracy: 0.5030\n",
      "Epoch 543/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1275 - accuracy: 0.6109 - val_loss: 1.5448 - val_accuracy: 0.4625\n",
      "Epoch 544/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1336 - accuracy: 0.6086 - val_loss: 1.5400 - val_accuracy: 0.4675\n",
      "Epoch 545/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1316 - accuracy: 0.6098 - val_loss: 1.4971 - val_accuracy: 0.4810\n",
      "Epoch 546/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1268 - accuracy: 0.6116 - val_loss: 1.4293 - val_accuracy: 0.5060\n",
      "Epoch 547/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1278 - accuracy: 0.6141 - val_loss: 1.8505 - val_accuracy: 0.4030\n",
      "Epoch 548/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1256 - accuracy: 0.6146 - val_loss: 1.4516 - val_accuracy: 0.4970\n",
      "Epoch 549/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1287 - accuracy: 0.6092 - val_loss: 1.7430 - val_accuracy: 0.4165\n",
      "Epoch 550/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1309 - accuracy: 0.6060 - val_loss: 1.5666 - val_accuracy: 0.4460\n",
      "Epoch 551/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1197 - accuracy: 0.6117 - val_loss: 1.3999 - val_accuracy: 0.5125\n",
      "Epoch 552/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1217 - accuracy: 0.6142 - val_loss: 1.6118 - val_accuracy: 0.4770\n",
      "Epoch 553/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1241 - accuracy: 0.6163 - val_loss: 1.3857 - val_accuracy: 0.5200\n",
      "Epoch 554/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1155 - accuracy: 0.6161 - val_loss: 1.5265 - val_accuracy: 0.4680\n",
      "Epoch 555/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1221 - accuracy: 0.6092 - val_loss: 1.5253 - val_accuracy: 0.5000\n",
      "Epoch 556/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1195 - accuracy: 0.6144 - val_loss: 1.7799 - val_accuracy: 0.4220\n",
      "Epoch 557/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1231 - accuracy: 0.6098 - val_loss: 1.4263 - val_accuracy: 0.5085\n",
      "Epoch 558/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1146 - accuracy: 0.6220 - val_loss: 1.5252 - val_accuracy: 0.4960\n",
      "Epoch 559/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1169 - accuracy: 0.6140 - val_loss: 1.4028 - val_accuracy: 0.5195\n",
      "Epoch 560/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1182 - accuracy: 0.6161 - val_loss: 1.5930 - val_accuracy: 0.4550\n",
      "Epoch 561/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1092 - accuracy: 0.6218 - val_loss: 1.7428 - val_accuracy: 0.4245\n",
      "Epoch 562/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1118 - accuracy: 0.6177 - val_loss: 1.4853 - val_accuracy: 0.4875\n",
      "Epoch 563/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1096 - accuracy: 0.6193 - val_loss: 1.4534 - val_accuracy: 0.4935\n",
      "Epoch 564/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1093 - accuracy: 0.6151 - val_loss: 1.4094 - val_accuracy: 0.5130\n",
      "Epoch 565/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1138 - accuracy: 0.6178 - val_loss: 1.4643 - val_accuracy: 0.4960\n",
      "Epoch 566/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1133 - accuracy: 0.6125 - val_loss: 1.4348 - val_accuracy: 0.5000\n",
      "Epoch 567/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1058 - accuracy: 0.6241 - val_loss: 1.4625 - val_accuracy: 0.4845\n",
      "Epoch 568/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1029 - accuracy: 0.6197 - val_loss: 1.6745 - val_accuracy: 0.4210\n",
      "Epoch 569/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1037 - accuracy: 0.6207 - val_loss: 1.4403 - val_accuracy: 0.4915\n",
      "Epoch 570/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0996 - accuracy: 0.6202 - val_loss: 1.4464 - val_accuracy: 0.5000\n",
      "Epoch 571/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1010 - accuracy: 0.6218 - val_loss: 1.4686 - val_accuracy: 0.4915\n",
      "Epoch 572/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1048 - accuracy: 0.6204 - val_loss: 1.5837 - val_accuracy: 0.4580\n",
      "Epoch 573/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1028 - accuracy: 0.6168 - val_loss: 1.4111 - val_accuracy: 0.5080\n",
      "Epoch 574/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0950 - accuracy: 0.6243 - val_loss: 1.5149 - val_accuracy: 0.4755\n",
      "Epoch 575/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1028 - accuracy: 0.6190 - val_loss: 1.5195 - val_accuracy: 0.4730\n",
      "Epoch 576/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1051 - accuracy: 0.6189 - val_loss: 1.6373 - val_accuracy: 0.4700\n",
      "Epoch 577/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1015 - accuracy: 0.6160 - val_loss: 1.4827 - val_accuracy: 0.4910\n",
      "Epoch 578/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0951 - accuracy: 0.6256 - val_loss: 1.4566 - val_accuracy: 0.4975\n",
      "Epoch 579/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0964 - accuracy: 0.6238 - val_loss: 1.7917 - val_accuracy: 0.4200\n",
      "Epoch 580/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0982 - accuracy: 0.6222 - val_loss: 1.4215 - val_accuracy: 0.5085\n",
      "Epoch 581/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0968 - accuracy: 0.6243 - val_loss: 1.4559 - val_accuracy: 0.5025\n",
      "Epoch 582/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0883 - accuracy: 0.6285 - val_loss: 1.5432 - val_accuracy: 0.4760\n",
      "Epoch 583/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0855 - accuracy: 0.6229 - val_loss: 1.4024 - val_accuracy: 0.5230\n",
      "Epoch 584/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0852 - accuracy: 0.6239 - val_loss: 1.5005 - val_accuracy: 0.4760\n",
      "Epoch 585/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0855 - accuracy: 0.6248 - val_loss: 1.5061 - val_accuracy: 0.4795\n",
      "Epoch 586/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0868 - accuracy: 0.6269 - val_loss: 1.4278 - val_accuracy: 0.5070\n",
      "Epoch 587/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0900 - accuracy: 0.6247 - val_loss: 1.4972 - val_accuracy: 0.4960\n",
      "Epoch 588/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0885 - accuracy: 0.6278 - val_loss: 1.9675 - val_accuracy: 0.3800\n",
      "Epoch 589/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0909 - accuracy: 0.6273 - val_loss: 1.3895 - val_accuracy: 0.5260\n",
      "Epoch 590/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0790 - accuracy: 0.6263 - val_loss: 1.5839 - val_accuracy: 0.4665\n",
      "Epoch 591/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0854 - accuracy: 0.6222 - val_loss: 1.5174 - val_accuracy: 0.4820\n",
      "Epoch 592/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0817 - accuracy: 0.6247 - val_loss: 1.4515 - val_accuracy: 0.4915\n",
      "Epoch 593/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0822 - accuracy: 0.6292 - val_loss: 1.4029 - val_accuracy: 0.5160\n",
      "Epoch 594/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0776 - accuracy: 0.6286 - val_loss: 1.4025 - val_accuracy: 0.5100\n",
      "Epoch 595/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0771 - accuracy: 0.6263 - val_loss: 1.5088 - val_accuracy: 0.4880\n",
      "Epoch 596/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0783 - accuracy: 0.6290 - val_loss: 1.7430 - val_accuracy: 0.4365\n",
      "Epoch 597/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0778 - accuracy: 0.6311 - val_loss: 1.3860 - val_accuracy: 0.5205\n",
      "Epoch 598/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0751 - accuracy: 0.6276 - val_loss: 1.3716 - val_accuracy: 0.5250\n",
      "Epoch 599/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0657 - accuracy: 0.6350 - val_loss: 1.4517 - val_accuracy: 0.4945\n",
      "Epoch 600/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0705 - accuracy: 0.6280 - val_loss: 1.5396 - val_accuracy: 0.4795\n",
      "Epoch 601/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0774 - accuracy: 0.6319 - val_loss: 1.4100 - val_accuracy: 0.5100\n",
      "Epoch 602/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0727 - accuracy: 0.6252 - val_loss: 1.5229 - val_accuracy: 0.4720\n",
      "Epoch 603/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0676 - accuracy: 0.6288 - val_loss: 1.4600 - val_accuracy: 0.4905\n",
      "Epoch 604/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0661 - accuracy: 0.6331 - val_loss: 1.3893 - val_accuracy: 0.5210\n",
      "Epoch 605/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0629 - accuracy: 0.6351 - val_loss: 1.5823 - val_accuracy: 0.4535\n",
      "Epoch 606/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0607 - accuracy: 0.6365 - val_loss: 1.5253 - val_accuracy: 0.4700\n",
      "Epoch 607/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0653 - accuracy: 0.6343 - val_loss: 1.5947 - val_accuracy: 0.4565\n",
      "Epoch 608/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0619 - accuracy: 0.6383 - val_loss: 1.4214 - val_accuracy: 0.5030\n",
      "Epoch 609/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0587 - accuracy: 0.6404 - val_loss: 1.5297 - val_accuracy: 0.4705\n",
      "Epoch 610/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0541 - accuracy: 0.6413 - val_loss: 1.5804 - val_accuracy: 0.4535\n",
      "Epoch 611/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0580 - accuracy: 0.6372 - val_loss: 1.5022 - val_accuracy: 0.4840\n",
      "Epoch 612/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0574 - accuracy: 0.6376 - val_loss: 1.4820 - val_accuracy: 0.4970\n",
      "Epoch 613/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0598 - accuracy: 0.6362 - val_loss: 1.5515 - val_accuracy: 0.4775\n",
      "Epoch 614/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0551 - accuracy: 0.6385 - val_loss: 1.6069 - val_accuracy: 0.4670\n",
      "Epoch 615/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0545 - accuracy: 0.6374 - val_loss: 1.5148 - val_accuracy: 0.4830\n",
      "Epoch 616/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0550 - accuracy: 0.6404 - val_loss: 1.4825 - val_accuracy: 0.4920\n",
      "Epoch 617/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0532 - accuracy: 0.6377 - val_loss: 1.5159 - val_accuracy: 0.4825\n",
      "Epoch 618/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0548 - accuracy: 0.6366 - val_loss: 1.8292 - val_accuracy: 0.4055\n",
      "Epoch 619/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0607 - accuracy: 0.6320 - val_loss: 1.4347 - val_accuracy: 0.5045\n",
      "Epoch 620/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0509 - accuracy: 0.6392 - val_loss: 1.4501 - val_accuracy: 0.4920\n",
      "Epoch 621/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0459 - accuracy: 0.6433 - val_loss: 1.4335 - val_accuracy: 0.4895\n",
      "Epoch 622/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0472 - accuracy: 0.6404 - val_loss: 1.4225 - val_accuracy: 0.5030\n",
      "Epoch 623/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0480 - accuracy: 0.6381 - val_loss: 1.6680 - val_accuracy: 0.4615\n",
      "Epoch 624/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0496 - accuracy: 0.6382 - val_loss: 1.4880 - val_accuracy: 0.4850\n",
      "Epoch 625/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0441 - accuracy: 0.6410 - val_loss: 1.4706 - val_accuracy: 0.4985\n",
      "Epoch 626/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0425 - accuracy: 0.6427 - val_loss: 1.4833 - val_accuracy: 0.4770\n",
      "Epoch 627/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0426 - accuracy: 0.6391 - val_loss: 1.4703 - val_accuracy: 0.4935\n",
      "Epoch 628/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0388 - accuracy: 0.6430 - val_loss: 1.4229 - val_accuracy: 0.5040\n",
      "Epoch 629/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0432 - accuracy: 0.6448 - val_loss: 1.5898 - val_accuracy: 0.4545\n",
      "Epoch 630/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0434 - accuracy: 0.6418 - val_loss: 1.4723 - val_accuracy: 0.5060\n",
      "Epoch 631/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0378 - accuracy: 0.6429 - val_loss: 1.4410 - val_accuracy: 0.5065\n",
      "Epoch 632/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0320 - accuracy: 0.6482 - val_loss: 1.5846 - val_accuracy: 0.4435\n",
      "Epoch 633/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0328 - accuracy: 0.6471 - val_loss: 1.5051 - val_accuracy: 0.4845\n",
      "Epoch 634/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0310 - accuracy: 0.6448 - val_loss: 1.4693 - val_accuracy: 0.4980\n",
      "Epoch 635/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0330 - accuracy: 0.6438 - val_loss: 1.3757 - val_accuracy: 0.5220\n",
      "Epoch 636/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0295 - accuracy: 0.6491 - val_loss: 1.4982 - val_accuracy: 0.4890\n",
      "Epoch 637/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0356 - accuracy: 0.6420 - val_loss: 1.4296 - val_accuracy: 0.5060\n",
      "Epoch 638/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0339 - accuracy: 0.6471 - val_loss: 1.6459 - val_accuracy: 0.4515\n",
      "Epoch 639/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0392 - accuracy: 0.6413 - val_loss: 1.5580 - val_accuracy: 0.4600\n",
      "Epoch 640/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0271 - accuracy: 0.6472 - val_loss: 1.4897 - val_accuracy: 0.4785\n",
      "Epoch 641/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0278 - accuracy: 0.6461 - val_loss: 1.4606 - val_accuracy: 0.4955\n",
      "Epoch 642/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0237 - accuracy: 0.6499 - val_loss: 1.4158 - val_accuracy: 0.5080\n",
      "Epoch 643/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0226 - accuracy: 0.6540 - val_loss: 1.4133 - val_accuracy: 0.5145\n",
      "Epoch 644/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0235 - accuracy: 0.6463 - val_loss: 1.5656 - val_accuracy: 0.4730\n",
      "Epoch 645/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0253 - accuracy: 0.6502 - val_loss: 1.4454 - val_accuracy: 0.5005\n",
      "Epoch 646/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0195 - accuracy: 0.6502 - val_loss: 1.5732 - val_accuracy: 0.4755\n",
      "Epoch 647/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0201 - accuracy: 0.6480 - val_loss: 1.3831 - val_accuracy: 0.5240\n",
      "Epoch 648/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0173 - accuracy: 0.6515 - val_loss: 1.9497 - val_accuracy: 0.3890\n",
      "Epoch 649/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0297 - accuracy: 0.6469 - val_loss: 1.4705 - val_accuracy: 0.4875\n",
      "Epoch 650/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0199 - accuracy: 0.6465 - val_loss: 1.6053 - val_accuracy: 0.4610\n",
      "Epoch 651/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0139 - accuracy: 0.6517 - val_loss: 1.7425 - val_accuracy: 0.4275\n",
      "Epoch 652/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0238 - accuracy: 0.6501 - val_loss: 1.3887 - val_accuracy: 0.5165\n",
      "Epoch 653/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0057 - accuracy: 0.6560 - val_loss: 1.6181 - val_accuracy: 0.4820\n",
      "Epoch 654/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0164 - accuracy: 0.6515 - val_loss: 1.5830 - val_accuracy: 0.4625\n",
      "Epoch 655/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0124 - accuracy: 0.6537 - val_loss: 1.5962 - val_accuracy: 0.4595\n",
      "Epoch 656/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0118 - accuracy: 0.6540 - val_loss: 1.3864 - val_accuracy: 0.5265\n",
      "Epoch 657/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0134 - accuracy: 0.6491 - val_loss: 1.4871 - val_accuracy: 0.4975\n",
      "Epoch 658/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0078 - accuracy: 0.6529 - val_loss: 1.6266 - val_accuracy: 0.4635\n",
      "Epoch 659/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0107 - accuracy: 0.6526 - val_loss: 1.4948 - val_accuracy: 0.4890\n",
      "Epoch 660/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0077 - accuracy: 0.6551 - val_loss: 1.8033 - val_accuracy: 0.4050\n",
      "Epoch 661/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0085 - accuracy: 0.6565 - val_loss: 1.3865 - val_accuracy: 0.5170\n",
      "Epoch 662/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0017 - accuracy: 0.6590 - val_loss: 1.4802 - val_accuracy: 0.4835\n",
      "Epoch 663/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9948 - accuracy: 0.6618 - val_loss: 1.5019 - val_accuracy: 0.4790\n",
      "Epoch 664/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9982 - accuracy: 0.6566 - val_loss: 1.4670 - val_accuracy: 0.5005\n",
      "Epoch 665/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9935 - accuracy: 0.6606 - val_loss: 1.4279 - val_accuracy: 0.5175\n",
      "Epoch 666/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9984 - accuracy: 0.6598 - val_loss: 1.3847 - val_accuracy: 0.5215\n",
      "Epoch 667/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0039 - accuracy: 0.6514 - val_loss: 1.5006 - val_accuracy: 0.4810\n",
      "Epoch 668/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9983 - accuracy: 0.6603 - val_loss: 1.4525 - val_accuracy: 0.5055\n",
      "Epoch 669/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9995 - accuracy: 0.6613 - val_loss: 1.4622 - val_accuracy: 0.4995\n",
      "Epoch 670/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9947 - accuracy: 0.6596 - val_loss: 1.4382 - val_accuracy: 0.5085\n",
      "Epoch 671/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9950 - accuracy: 0.6571 - val_loss: 1.4501 - val_accuracy: 0.5070\n",
      "Epoch 672/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.0020 - accuracy: 0.6564 - val_loss: 1.4296 - val_accuracy: 0.5060\n",
      "Epoch 673/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9927 - accuracy: 0.6623 - val_loss: 1.4549 - val_accuracy: 0.5040\n",
      "Epoch 674/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9934 - accuracy: 0.6602 - val_loss: 1.4887 - val_accuracy: 0.4860\n",
      "Epoch 675/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9854 - accuracy: 0.6605 - val_loss: 1.5593 - val_accuracy: 0.4665\n",
      "Epoch 676/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9866 - accuracy: 0.6623 - val_loss: 1.4901 - val_accuracy: 0.4865\n",
      "Epoch 677/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9877 - accuracy: 0.6661 - val_loss: 1.4201 - val_accuracy: 0.5140\n",
      "Epoch 678/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9805 - accuracy: 0.6657 - val_loss: 1.7021 - val_accuracy: 0.4440\n",
      "Epoch 679/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9872 - accuracy: 0.6625 - val_loss: 1.5172 - val_accuracy: 0.4785\n",
      "Epoch 680/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9832 - accuracy: 0.6640 - val_loss: 1.6365 - val_accuracy: 0.4690\n",
      "Epoch 681/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9842 - accuracy: 0.6634 - val_loss: 1.4357 - val_accuracy: 0.5000\n",
      "Epoch 682/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9792 - accuracy: 0.6663 - val_loss: 1.5008 - val_accuracy: 0.4990\n",
      "Epoch 683/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9857 - accuracy: 0.6637 - val_loss: 1.7298 - val_accuracy: 0.4180\n",
      "Epoch 684/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9822 - accuracy: 0.6621 - val_loss: 1.4766 - val_accuracy: 0.4945\n",
      "Epoch 685/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9748 - accuracy: 0.6641 - val_loss: 1.7211 - val_accuracy: 0.4315\n",
      "Epoch 686/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9837 - accuracy: 0.6678 - val_loss: 1.5755 - val_accuracy: 0.4685\n",
      "Epoch 687/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9751 - accuracy: 0.6653 - val_loss: 1.5299 - val_accuracy: 0.4875\n",
      "Epoch 688/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9804 - accuracy: 0.6650 - val_loss: 1.6781 - val_accuracy: 0.4495\n",
      "Epoch 689/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9713 - accuracy: 0.6716 - val_loss: 1.8706 - val_accuracy: 0.4080\n",
      "Epoch 690/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9728 - accuracy: 0.6683 - val_loss: 1.4808 - val_accuracy: 0.4955\n",
      "Epoch 691/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9720 - accuracy: 0.6688 - val_loss: 1.5589 - val_accuracy: 0.4655\n",
      "Epoch 692/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9693 - accuracy: 0.6682 - val_loss: 1.4933 - val_accuracy: 0.4935\n",
      "Epoch 693/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9734 - accuracy: 0.6688 - val_loss: 1.4417 - val_accuracy: 0.5085\n",
      "Epoch 694/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9669 - accuracy: 0.6677 - val_loss: 1.4442 - val_accuracy: 0.5025\n",
      "Epoch 695/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9705 - accuracy: 0.6656 - val_loss: 1.5172 - val_accuracy: 0.4765\n",
      "Epoch 696/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9630 - accuracy: 0.6728 - val_loss: 1.4342 - val_accuracy: 0.5115\n",
      "Epoch 697/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9662 - accuracy: 0.6710 - val_loss: 1.5089 - val_accuracy: 0.4760\n",
      "Epoch 698/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9632 - accuracy: 0.6724 - val_loss: 1.4879 - val_accuracy: 0.4985\n",
      "Epoch 699/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9622 - accuracy: 0.6750 - val_loss: 1.4509 - val_accuracy: 0.5030\n",
      "Epoch 700/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9606 - accuracy: 0.6692 - val_loss: 1.5572 - val_accuracy: 0.4735\n",
      "Epoch 701/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9616 - accuracy: 0.6739 - val_loss: 1.5219 - val_accuracy: 0.4875\n",
      "Epoch 702/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9579 - accuracy: 0.6753 - val_loss: 1.5390 - val_accuracy: 0.4860\n",
      "Epoch 703/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9628 - accuracy: 0.6724 - val_loss: 1.4175 - val_accuracy: 0.5020\n",
      "Epoch 704/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9541 - accuracy: 0.6729 - val_loss: 1.4613 - val_accuracy: 0.5100\n",
      "Epoch 705/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9580 - accuracy: 0.6755 - val_loss: 1.5023 - val_accuracy: 0.4905\n",
      "Epoch 706/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9569 - accuracy: 0.6745 - val_loss: 1.5365 - val_accuracy: 0.4790\n",
      "Epoch 707/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9509 - accuracy: 0.6759 - val_loss: 1.5288 - val_accuracy: 0.4940\n",
      "Epoch 708/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9511 - accuracy: 0.6759 - val_loss: 1.5559 - val_accuracy: 0.4725\n",
      "Epoch 709/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9507 - accuracy: 0.6746 - val_loss: 1.4383 - val_accuracy: 0.5135\n",
      "Epoch 710/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9435 - accuracy: 0.6797 - val_loss: 1.6150 - val_accuracy: 0.4685\n",
      "Epoch 711/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9424 - accuracy: 0.6781 - val_loss: 1.5181 - val_accuracy: 0.4850\n",
      "Epoch 712/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9482 - accuracy: 0.6734 - val_loss: 1.4727 - val_accuracy: 0.4955\n",
      "Epoch 713/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9452 - accuracy: 0.6811 - val_loss: 1.5234 - val_accuracy: 0.4825\n",
      "Epoch 714/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9459 - accuracy: 0.6790 - val_loss: 1.5966 - val_accuracy: 0.4575\n",
      "Epoch 715/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9423 - accuracy: 0.6787 - val_loss: 1.5789 - val_accuracy: 0.4585\n",
      "Epoch 716/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9475 - accuracy: 0.6798 - val_loss: 1.5906 - val_accuracy: 0.4675\n",
      "Epoch 717/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9397 - accuracy: 0.6834 - val_loss: 1.5965 - val_accuracy: 0.4500\n",
      "Epoch 718/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9439 - accuracy: 0.6796 - val_loss: 1.4028 - val_accuracy: 0.5120\n",
      "Epoch 719/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9397 - accuracy: 0.6796 - val_loss: 1.4346 - val_accuracy: 0.5090\n",
      "Epoch 720/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9383 - accuracy: 0.6830 - val_loss: 1.4584 - val_accuracy: 0.4980\n",
      "Epoch 721/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9331 - accuracy: 0.6852 - val_loss: 1.6690 - val_accuracy: 0.4450\n",
      "Epoch 722/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9340 - accuracy: 0.6853 - val_loss: 1.4568 - val_accuracy: 0.5070\n",
      "Epoch 723/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9330 - accuracy: 0.6873 - val_loss: 1.4740 - val_accuracy: 0.5060\n",
      "Epoch 724/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9342 - accuracy: 0.6795 - val_loss: 1.4452 - val_accuracy: 0.5085\n",
      "Epoch 725/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9274 - accuracy: 0.6896 - val_loss: 1.4502 - val_accuracy: 0.5120\n",
      "Epoch 726/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9331 - accuracy: 0.6856 - val_loss: 1.4972 - val_accuracy: 0.4875\n",
      "Epoch 727/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9266 - accuracy: 0.6886 - val_loss: 1.4280 - val_accuracy: 0.5050\n",
      "Epoch 728/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9290 - accuracy: 0.6851 - val_loss: 2.0420 - val_accuracy: 0.3930\n",
      "Epoch 729/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9364 - accuracy: 0.6837 - val_loss: 1.6848 - val_accuracy: 0.4605\n",
      "Epoch 730/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9280 - accuracy: 0.6821 - val_loss: 1.9298 - val_accuracy: 0.4315\n",
      "Epoch 731/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9329 - accuracy: 0.6844 - val_loss: 1.4328 - val_accuracy: 0.5165\n",
      "Epoch 732/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9208 - accuracy: 0.6873 - val_loss: 1.3983 - val_accuracy: 0.5155\n",
      "Epoch 733/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9225 - accuracy: 0.6875 - val_loss: 1.4858 - val_accuracy: 0.5030\n",
      "Epoch 734/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9280 - accuracy: 0.6865 - val_loss: 1.4426 - val_accuracy: 0.5170\n",
      "Epoch 735/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9286 - accuracy: 0.6844 - val_loss: 1.4337 - val_accuracy: 0.5135\n",
      "Epoch 736/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9166 - accuracy: 0.6888 - val_loss: 2.0298 - val_accuracy: 0.4245\n",
      "Epoch 737/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9257 - accuracy: 0.6835 - val_loss: 1.4648 - val_accuracy: 0.4985\n",
      "Epoch 738/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9244 - accuracy: 0.6857 - val_loss: 1.5540 - val_accuracy: 0.4640\n",
      "Epoch 739/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9200 - accuracy: 0.6879 - val_loss: 1.6260 - val_accuracy: 0.4555\n",
      "Epoch 740/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9173 - accuracy: 0.6895 - val_loss: 1.5134 - val_accuracy: 0.4895\n",
      "Epoch 741/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9209 - accuracy: 0.6887 - val_loss: 1.3786 - val_accuracy: 0.5260\n",
      "Epoch 742/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9095 - accuracy: 0.6905 - val_loss: 1.3942 - val_accuracy: 0.5310\n",
      "Epoch 743/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9130 - accuracy: 0.6912 - val_loss: 1.5939 - val_accuracy: 0.4875\n",
      "Epoch 744/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9140 - accuracy: 0.6886 - val_loss: 1.5265 - val_accuracy: 0.4810\n",
      "Epoch 745/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9043 - accuracy: 0.6960 - val_loss: 1.4331 - val_accuracy: 0.5170\n",
      "Epoch 746/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9083 - accuracy: 0.6923 - val_loss: 1.4953 - val_accuracy: 0.4915\n",
      "Epoch 747/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9085 - accuracy: 0.6937 - val_loss: 1.9319 - val_accuracy: 0.3960\n",
      "Epoch 748/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9169 - accuracy: 0.6877 - val_loss: 1.4657 - val_accuracy: 0.4920\n",
      "Epoch 749/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8999 - accuracy: 0.6985 - val_loss: 1.4905 - val_accuracy: 0.4935\n",
      "Epoch 750/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9013 - accuracy: 0.6945 - val_loss: 1.5525 - val_accuracy: 0.4865\n",
      "Epoch 751/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9020 - accuracy: 0.6932 - val_loss: 1.4938 - val_accuracy: 0.4880\n",
      "Epoch 752/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8972 - accuracy: 0.7014 - val_loss: 1.5534 - val_accuracy: 0.4840\n",
      "Epoch 753/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9038 - accuracy: 0.6924 - val_loss: 1.5392 - val_accuracy: 0.4810\n",
      "Epoch 754/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8971 - accuracy: 0.6973 - val_loss: 1.6322 - val_accuracy: 0.4665\n",
      "Epoch 755/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9016 - accuracy: 0.6964 - val_loss: 1.4062 - val_accuracy: 0.5100\n",
      "Epoch 756/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8960 - accuracy: 0.6965 - val_loss: 1.4425 - val_accuracy: 0.5120\n",
      "Epoch 757/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8985 - accuracy: 0.6957 - val_loss: 1.5134 - val_accuracy: 0.4940\n",
      "Epoch 758/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8933 - accuracy: 0.6978 - val_loss: 1.5096 - val_accuracy: 0.4975\n",
      "Epoch 759/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.9015 - accuracy: 0.6962 - val_loss: 1.5835 - val_accuracy: 0.4695\n",
      "Epoch 760/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8920 - accuracy: 0.6986 - val_loss: 1.5554 - val_accuracy: 0.4885\n",
      "Epoch 761/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8940 - accuracy: 0.6958 - val_loss: 1.5059 - val_accuracy: 0.5015\n",
      "Epoch 762/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8962 - accuracy: 0.6949 - val_loss: 1.6125 - val_accuracy: 0.4525\n",
      "Epoch 763/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8868 - accuracy: 0.7032 - val_loss: 1.7503 - val_accuracy: 0.4410\n",
      "Epoch 764/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8850 - accuracy: 0.7041 - val_loss: 1.5492 - val_accuracy: 0.4920\n",
      "Epoch 765/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8965 - accuracy: 0.6967 - val_loss: 1.5406 - val_accuracy: 0.4780\n",
      "Epoch 766/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8817 - accuracy: 0.7040 - val_loss: 1.6333 - val_accuracy: 0.4695\n",
      "Epoch 767/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8868 - accuracy: 0.7014 - val_loss: 1.5128 - val_accuracy: 0.4940\n",
      "Epoch 768/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8829 - accuracy: 0.7029 - val_loss: 1.6517 - val_accuracy: 0.4605\n",
      "Epoch 769/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8828 - accuracy: 0.7050 - val_loss: 1.5304 - val_accuracy: 0.4730\n",
      "Epoch 770/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8822 - accuracy: 0.7030 - val_loss: 1.5415 - val_accuracy: 0.4900\n",
      "Epoch 771/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8792 - accuracy: 0.7039 - val_loss: 1.4330 - val_accuracy: 0.5210\n",
      "Epoch 772/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8811 - accuracy: 0.6996 - val_loss: 1.5248 - val_accuracy: 0.4930\n",
      "Epoch 773/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8800 - accuracy: 0.7033 - val_loss: 1.4885 - val_accuracy: 0.4880\n",
      "Epoch 774/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8708 - accuracy: 0.7099 - val_loss: 1.3883 - val_accuracy: 0.5330\n",
      "Epoch 775/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8758 - accuracy: 0.7076 - val_loss: 1.5532 - val_accuracy: 0.4905\n",
      "Epoch 776/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8856 - accuracy: 0.7042 - val_loss: 1.5445 - val_accuracy: 0.5015\n",
      "Epoch 777/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8745 - accuracy: 0.7111 - val_loss: 1.8398 - val_accuracy: 0.4380\n",
      "Epoch 778/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8786 - accuracy: 0.7047 - val_loss: 1.7261 - val_accuracy: 0.4470\n",
      "Epoch 779/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8746 - accuracy: 0.7045 - val_loss: 1.4429 - val_accuracy: 0.5110\n",
      "Epoch 780/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8669 - accuracy: 0.7071 - val_loss: 1.5247 - val_accuracy: 0.4955\n",
      "Epoch 781/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8689 - accuracy: 0.7061 - val_loss: 1.5274 - val_accuracy: 0.4845\n",
      "Epoch 782/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8702 - accuracy: 0.7082 - val_loss: 1.4774 - val_accuracy: 0.5065\n",
      "Epoch 783/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8726 - accuracy: 0.7079 - val_loss: 1.5392 - val_accuracy: 0.4860\n",
      "Epoch 784/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8644 - accuracy: 0.7091 - val_loss: 1.4489 - val_accuracy: 0.5010\n",
      "Epoch 785/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8577 - accuracy: 0.7095 - val_loss: 1.5100 - val_accuracy: 0.4920\n",
      "Epoch 786/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8623 - accuracy: 0.7109 - val_loss: 1.6465 - val_accuracy: 0.4690\n",
      "Epoch 787/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8622 - accuracy: 0.7094 - val_loss: 1.6229 - val_accuracy: 0.4705\n",
      "Epoch 788/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8549 - accuracy: 0.7158 - val_loss: 1.8148 - val_accuracy: 0.4170\n",
      "Epoch 789/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8679 - accuracy: 0.7115 - val_loss: 1.4833 - val_accuracy: 0.4980\n",
      "Epoch 790/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8559 - accuracy: 0.7143 - val_loss: 1.6337 - val_accuracy: 0.4655\n",
      "Epoch 791/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8585 - accuracy: 0.7121 - val_loss: 1.5515 - val_accuracy: 0.4810\n",
      "Epoch 792/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8558 - accuracy: 0.7152 - val_loss: 1.6918 - val_accuracy: 0.4410\n",
      "Epoch 793/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8595 - accuracy: 0.7144 - val_loss: 1.5101 - val_accuracy: 0.4905\n",
      "Epoch 794/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8489 - accuracy: 0.7182 - val_loss: 1.6043 - val_accuracy: 0.4655\n",
      "Epoch 795/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8533 - accuracy: 0.7108 - val_loss: 1.7466 - val_accuracy: 0.4485\n",
      "Epoch 796/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8483 - accuracy: 0.7147 - val_loss: 1.4741 - val_accuracy: 0.4945\n",
      "Epoch 797/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8442 - accuracy: 0.7226 - val_loss: 1.8351 - val_accuracy: 0.4385\n",
      "Epoch 798/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8498 - accuracy: 0.7167 - val_loss: 1.4801 - val_accuracy: 0.5070\n",
      "Epoch 799/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8440 - accuracy: 0.7137 - val_loss: 1.5765 - val_accuracy: 0.4720\n",
      "Epoch 800/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8460 - accuracy: 0.7177 - val_loss: 1.5346 - val_accuracy: 0.4980\n",
      "Epoch 801/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8466 - accuracy: 0.7183 - val_loss: 1.4191 - val_accuracy: 0.5235\n",
      "Epoch 802/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8440 - accuracy: 0.7204 - val_loss: 1.4758 - val_accuracy: 0.5135\n",
      "Epoch 803/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8354 - accuracy: 0.7263 - val_loss: 1.5245 - val_accuracy: 0.4990\n",
      "Epoch 804/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8358 - accuracy: 0.7223 - val_loss: 1.4056 - val_accuracy: 0.5190\n",
      "Epoch 805/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8422 - accuracy: 0.7154 - val_loss: 1.7981 - val_accuracy: 0.4125\n",
      "Epoch 806/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8465 - accuracy: 0.7199 - val_loss: 1.4643 - val_accuracy: 0.5040\n",
      "Epoch 807/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8369 - accuracy: 0.7207 - val_loss: 1.6135 - val_accuracy: 0.4775\n",
      "Epoch 808/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8421 - accuracy: 0.7214 - val_loss: 1.7470 - val_accuracy: 0.4290\n",
      "Epoch 809/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8383 - accuracy: 0.7206 - val_loss: 1.6028 - val_accuracy: 0.4820\n",
      "Epoch 810/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8356 - accuracy: 0.7204 - val_loss: 1.6496 - val_accuracy: 0.4665\n",
      "Epoch 811/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8336 - accuracy: 0.7232 - val_loss: 1.5660 - val_accuracy: 0.5015\n",
      "Epoch 812/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8341 - accuracy: 0.7186 - val_loss: 1.4977 - val_accuracy: 0.5000\n",
      "Epoch 813/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8335 - accuracy: 0.7214 - val_loss: 1.4062 - val_accuracy: 0.5235\n",
      "Epoch 814/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8239 - accuracy: 0.7271 - val_loss: 1.4940 - val_accuracy: 0.4990\n",
      "Epoch 815/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8219 - accuracy: 0.7300 - val_loss: 1.5140 - val_accuracy: 0.4915\n",
      "Epoch 816/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8320 - accuracy: 0.7208 - val_loss: 1.6039 - val_accuracy: 0.4785\n",
      "Epoch 817/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8341 - accuracy: 0.7235 - val_loss: 1.5720 - val_accuracy: 0.4725\n",
      "Epoch 818/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8232 - accuracy: 0.7281 - val_loss: 1.8655 - val_accuracy: 0.4075\n",
      "Epoch 819/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8285 - accuracy: 0.7233 - val_loss: 1.4678 - val_accuracy: 0.5030\n",
      "Epoch 820/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8253 - accuracy: 0.7232 - val_loss: 1.5841 - val_accuracy: 0.4815\n",
      "Epoch 821/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8235 - accuracy: 0.7252 - val_loss: 1.4483 - val_accuracy: 0.5190\n",
      "Epoch 822/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8177 - accuracy: 0.7262 - val_loss: 1.4933 - val_accuracy: 0.5025\n",
      "Epoch 823/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8164 - accuracy: 0.7295 - val_loss: 2.0654 - val_accuracy: 0.4265\n",
      "Epoch 824/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8323 - accuracy: 0.7229 - val_loss: 1.5010 - val_accuracy: 0.4795\n",
      "Epoch 825/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8246 - accuracy: 0.7252 - val_loss: 1.4256 - val_accuracy: 0.5215\n",
      "Epoch 826/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8190 - accuracy: 0.7302 - val_loss: 1.5404 - val_accuracy: 0.4810\n",
      "Epoch 827/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8116 - accuracy: 0.7312 - val_loss: 1.5335 - val_accuracy: 0.4975\n",
      "Epoch 828/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8152 - accuracy: 0.7299 - val_loss: 1.6897 - val_accuracy: 0.4770\n",
      "Epoch 829/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8113 - accuracy: 0.7302 - val_loss: 1.7822 - val_accuracy: 0.4470\n",
      "Epoch 830/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8198 - accuracy: 0.7235 - val_loss: 1.8112 - val_accuracy: 0.4240\n",
      "Epoch 831/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8158 - accuracy: 0.7328 - val_loss: 1.7406 - val_accuracy: 0.4285\n",
      "Epoch 832/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8081 - accuracy: 0.7329 - val_loss: 1.5269 - val_accuracy: 0.5035\n",
      "Epoch 833/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8075 - accuracy: 0.7351 - val_loss: 1.8238 - val_accuracy: 0.4540\n",
      "Epoch 834/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8122 - accuracy: 0.7284 - val_loss: 1.4269 - val_accuracy: 0.5220\n",
      "Epoch 835/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8000 - accuracy: 0.7358 - val_loss: 1.7116 - val_accuracy: 0.4610\n",
      "Epoch 836/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7967 - accuracy: 0.7358 - val_loss: 1.5134 - val_accuracy: 0.4895\n",
      "Epoch 837/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8094 - accuracy: 0.7340 - val_loss: 1.5298 - val_accuracy: 0.4860\n",
      "Epoch 838/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.8008 - accuracy: 0.7364 - val_loss: 1.5982 - val_accuracy: 0.4795\n",
      "Epoch 839/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7992 - accuracy: 0.7384 - val_loss: 1.4605 - val_accuracy: 0.5025\n",
      "Epoch 840/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7918 - accuracy: 0.7406 - val_loss: 1.4682 - val_accuracy: 0.5225\n",
      "Epoch 841/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7897 - accuracy: 0.7433 - val_loss: 1.5809 - val_accuracy: 0.4700\n",
      "Epoch 842/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7942 - accuracy: 0.7398 - val_loss: 1.5287 - val_accuracy: 0.5010\n",
      "Epoch 843/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7949 - accuracy: 0.7406 - val_loss: 1.4510 - val_accuracy: 0.5160\n",
      "Epoch 844/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7857 - accuracy: 0.7443 - val_loss: 1.6854 - val_accuracy: 0.4495\n",
      "Epoch 845/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7965 - accuracy: 0.7360 - val_loss: 1.4247 - val_accuracy: 0.5270\n",
      "Epoch 846/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7873 - accuracy: 0.7440 - val_loss: 1.4984 - val_accuracy: 0.4935\n",
      "Epoch 847/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7855 - accuracy: 0.7415 - val_loss: 1.6306 - val_accuracy: 0.4860\n",
      "Epoch 848/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7834 - accuracy: 0.7442 - val_loss: 1.5213 - val_accuracy: 0.4980\n",
      "Epoch 849/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7920 - accuracy: 0.7393 - val_loss: 1.4510 - val_accuracy: 0.5080\n",
      "Epoch 850/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7803 - accuracy: 0.7443 - val_loss: 1.4706 - val_accuracy: 0.5050\n",
      "Epoch 851/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7839 - accuracy: 0.7384 - val_loss: 1.7351 - val_accuracy: 0.4685\n",
      "Epoch 852/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7844 - accuracy: 0.7448 - val_loss: 1.6009 - val_accuracy: 0.4685\n",
      "Epoch 853/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7897 - accuracy: 0.7403 - val_loss: 1.5380 - val_accuracy: 0.4885\n",
      "Epoch 854/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7782 - accuracy: 0.7456 - val_loss: 1.6387 - val_accuracy: 0.4710\n",
      "Epoch 855/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7785 - accuracy: 0.7477 - val_loss: 1.5898 - val_accuracy: 0.4935\n",
      "Epoch 856/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7808 - accuracy: 0.7465 - val_loss: 1.7463 - val_accuracy: 0.4445\n",
      "Epoch 857/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7756 - accuracy: 0.7444 - val_loss: 1.5830 - val_accuracy: 0.4735\n",
      "Epoch 858/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7701 - accuracy: 0.7486 - val_loss: 1.4197 - val_accuracy: 0.5205\n",
      "Epoch 859/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7713 - accuracy: 0.7454 - val_loss: 1.6092 - val_accuracy: 0.4800\n",
      "Epoch 860/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7746 - accuracy: 0.7470 - val_loss: 1.7602 - val_accuracy: 0.4580\n",
      "Epoch 861/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7721 - accuracy: 0.7514 - val_loss: 1.5388 - val_accuracy: 0.4885\n",
      "Epoch 862/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7752 - accuracy: 0.7473 - val_loss: 1.6225 - val_accuracy: 0.4650\n",
      "Epoch 863/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7710 - accuracy: 0.7461 - val_loss: 1.7681 - val_accuracy: 0.4460\n",
      "Epoch 864/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7780 - accuracy: 0.7477 - val_loss: 1.5986 - val_accuracy: 0.4875\n",
      "Epoch 865/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7670 - accuracy: 0.7509 - val_loss: 1.5096 - val_accuracy: 0.5085\n",
      "Epoch 866/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7669 - accuracy: 0.7511 - val_loss: 1.5168 - val_accuracy: 0.5000\n",
      "Epoch 867/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7645 - accuracy: 0.7481 - val_loss: 1.8278 - val_accuracy: 0.4210\n",
      "Epoch 868/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7631 - accuracy: 0.7529 - val_loss: 1.5264 - val_accuracy: 0.5060\n",
      "Epoch 869/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7666 - accuracy: 0.7442 - val_loss: 1.4453 - val_accuracy: 0.5185\n",
      "Epoch 870/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7665 - accuracy: 0.7472 - val_loss: 1.5283 - val_accuracy: 0.4840\n",
      "Epoch 871/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7636 - accuracy: 0.7492 - val_loss: 1.5189 - val_accuracy: 0.4945\n",
      "Epoch 872/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7727 - accuracy: 0.7468 - val_loss: 1.5753 - val_accuracy: 0.4805\n",
      "Epoch 873/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7570 - accuracy: 0.7538 - val_loss: 1.6397 - val_accuracy: 0.4820\n",
      "Epoch 874/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7608 - accuracy: 0.7516 - val_loss: 2.1090 - val_accuracy: 0.3945\n",
      "Epoch 875/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7695 - accuracy: 0.7482 - val_loss: 1.6857 - val_accuracy: 0.4595\n",
      "Epoch 876/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7558 - accuracy: 0.7513 - val_loss: 1.5088 - val_accuracy: 0.5120\n",
      "Epoch 877/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7493 - accuracy: 0.7600 - val_loss: 1.4700 - val_accuracy: 0.5070\n",
      "Epoch 878/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7501 - accuracy: 0.7594 - val_loss: 1.4603 - val_accuracy: 0.5045\n",
      "Epoch 879/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7455 - accuracy: 0.7585 - val_loss: 1.6570 - val_accuracy: 0.4580\n",
      "Epoch 880/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7555 - accuracy: 0.7536 - val_loss: 1.5623 - val_accuracy: 0.4900\n",
      "Epoch 881/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7477 - accuracy: 0.7538 - val_loss: 1.4249 - val_accuracy: 0.5265\n",
      "Epoch 882/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7420 - accuracy: 0.7624 - val_loss: 1.5680 - val_accuracy: 0.4930\n",
      "Epoch 883/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7496 - accuracy: 0.7549 - val_loss: 1.5953 - val_accuracy: 0.5020\n",
      "Epoch 884/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7450 - accuracy: 0.7577 - val_loss: 1.5769 - val_accuracy: 0.4925\n",
      "Epoch 885/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7399 - accuracy: 0.7619 - val_loss: 1.7247 - val_accuracy: 0.4470\n",
      "Epoch 886/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7481 - accuracy: 0.7554 - val_loss: 1.4560 - val_accuracy: 0.5220\n",
      "Epoch 887/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7402 - accuracy: 0.7607 - val_loss: 1.6045 - val_accuracy: 0.4880\n",
      "Epoch 888/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7349 - accuracy: 0.7647 - val_loss: 1.5481 - val_accuracy: 0.5030\n",
      "Epoch 889/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7334 - accuracy: 0.7648 - val_loss: 1.5761 - val_accuracy: 0.4800\n",
      "Epoch 890/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7341 - accuracy: 0.7627 - val_loss: 1.5381 - val_accuracy: 0.5075\n",
      "Epoch 891/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7322 - accuracy: 0.7659 - val_loss: 2.4270 - val_accuracy: 0.3675\n",
      "Epoch 892/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7520 - accuracy: 0.7607 - val_loss: 1.7804 - val_accuracy: 0.4645\n",
      "Epoch 893/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7404 - accuracy: 0.7585 - val_loss: 1.4218 - val_accuracy: 0.5275\n",
      "Epoch 894/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7272 - accuracy: 0.7687 - val_loss: 1.4771 - val_accuracy: 0.5090\n",
      "Epoch 895/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7322 - accuracy: 0.7613 - val_loss: 1.8006 - val_accuracy: 0.4410\n",
      "Epoch 896/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7332 - accuracy: 0.7650 - val_loss: 1.9592 - val_accuracy: 0.4025\n",
      "Epoch 897/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7262 - accuracy: 0.7685 - val_loss: 1.4307 - val_accuracy: 0.5190\n",
      "Epoch 898/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7202 - accuracy: 0.7693 - val_loss: 1.4764 - val_accuracy: 0.5110\n",
      "Epoch 899/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7264 - accuracy: 0.7649 - val_loss: 1.7262 - val_accuracy: 0.4435\n",
      "Epoch 900/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7249 - accuracy: 0.7661 - val_loss: 1.5691 - val_accuracy: 0.4885\n",
      "Epoch 901/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7332 - accuracy: 0.7655 - val_loss: 1.7829 - val_accuracy: 0.4605\n",
      "Epoch 902/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7303 - accuracy: 0.7648 - val_loss: 1.7987 - val_accuracy: 0.4560\n",
      "Epoch 903/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7265 - accuracy: 0.7665 - val_loss: 1.5037 - val_accuracy: 0.5050\n",
      "Epoch 904/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7144 - accuracy: 0.7721 - val_loss: 1.5037 - val_accuracy: 0.5090\n",
      "Epoch 905/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7137 - accuracy: 0.7751 - val_loss: 1.6005 - val_accuracy: 0.4965\n",
      "Epoch 906/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7159 - accuracy: 0.7705 - val_loss: 1.4899 - val_accuracy: 0.5115\n",
      "Epoch 907/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7160 - accuracy: 0.7695 - val_loss: 1.5670 - val_accuracy: 0.4990\n",
      "Epoch 908/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7122 - accuracy: 0.7768 - val_loss: 2.0912 - val_accuracy: 0.4425\n",
      "Epoch 909/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7167 - accuracy: 0.7748 - val_loss: 1.5320 - val_accuracy: 0.5080\n",
      "Epoch 910/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7159 - accuracy: 0.7705 - val_loss: 1.6049 - val_accuracy: 0.4805\n",
      "Epoch 911/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7173 - accuracy: 0.7694 - val_loss: 1.5369 - val_accuracy: 0.4815\n",
      "Epoch 912/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7153 - accuracy: 0.7707 - val_loss: 1.5020 - val_accuracy: 0.5055\n",
      "Epoch 913/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7087 - accuracy: 0.7714 - val_loss: 1.7089 - val_accuracy: 0.4585\n",
      "Epoch 914/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7131 - accuracy: 0.7698 - val_loss: 1.7321 - val_accuracy: 0.4740\n",
      "Epoch 915/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7060 - accuracy: 0.7767 - val_loss: 1.7124 - val_accuracy: 0.4830\n",
      "Epoch 916/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7160 - accuracy: 0.7724 - val_loss: 1.7034 - val_accuracy: 0.4545\n",
      "Epoch 917/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7112 - accuracy: 0.7713 - val_loss: 1.6537 - val_accuracy: 0.4780\n",
      "Epoch 918/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7057 - accuracy: 0.7757 - val_loss: 1.5286 - val_accuracy: 0.5005\n",
      "Epoch 919/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7014 - accuracy: 0.7762 - val_loss: 1.5693 - val_accuracy: 0.4820\n",
      "Epoch 920/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7018 - accuracy: 0.7747 - val_loss: 1.5075 - val_accuracy: 0.5135\n",
      "Epoch 921/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7010 - accuracy: 0.7821 - val_loss: 1.5982 - val_accuracy: 0.4945\n",
      "Epoch 922/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6985 - accuracy: 0.7763 - val_loss: 1.5735 - val_accuracy: 0.4945\n",
      "Epoch 923/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.7010 - accuracy: 0.7808 - val_loss: 1.7294 - val_accuracy: 0.4595\n",
      "Epoch 924/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6945 - accuracy: 0.7815 - val_loss: 1.4615 - val_accuracy: 0.5180\n",
      "Epoch 925/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6887 - accuracy: 0.7825 - val_loss: 1.5005 - val_accuracy: 0.5030\n",
      "Epoch 926/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6921 - accuracy: 0.7802 - val_loss: 1.4903 - val_accuracy: 0.5075\n",
      "Epoch 927/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6887 - accuracy: 0.7822 - val_loss: 1.5502 - val_accuracy: 0.4925\n",
      "Epoch 928/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6920 - accuracy: 0.7809 - val_loss: 1.5168 - val_accuracy: 0.5095\n",
      "Epoch 929/1000\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6856 - accuracy: 0.7818 - val_loss: 1.5172 - val_accuracy: 0.5060\n",
      "Epoch 930/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6849 - accuracy: 0.7833 - val_loss: 1.8158 - val_accuracy: 0.4420\n",
      "Epoch 931/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6934 - accuracy: 0.7788 - val_loss: 1.4700 - val_accuracy: 0.5195\n",
      "Epoch 932/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6786 - accuracy: 0.7865 - val_loss: 1.5478 - val_accuracy: 0.5005\n",
      "Epoch 933/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6782 - accuracy: 0.7866 - val_loss: 1.5322 - val_accuracy: 0.5020\n",
      "Epoch 934/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6761 - accuracy: 0.7889 - val_loss: 1.9382 - val_accuracy: 0.4380\n",
      "Epoch 935/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6868 - accuracy: 0.7856 - val_loss: 1.8394 - val_accuracy: 0.4420\n",
      "Epoch 936/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6878 - accuracy: 0.7820 - val_loss: 1.6831 - val_accuracy: 0.4750\n",
      "Epoch 937/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6723 - accuracy: 0.7892 - val_loss: 1.5545 - val_accuracy: 0.5140\n",
      "Epoch 938/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6747 - accuracy: 0.7878 - val_loss: 1.6124 - val_accuracy: 0.4965\n",
      "Epoch 939/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6847 - accuracy: 0.7873 - val_loss: 1.5919 - val_accuracy: 0.4930\n",
      "Epoch 940/1000\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6767 - accuracy: 0.7846 - val_loss: 1.6209 - val_accuracy: 0.4790\n",
      "Epoch 941/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6643 - accuracy: 0.7905 - val_loss: 1.6786 - val_accuracy: 0.4800\n",
      "Epoch 942/1000\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.6699 - accuracy: 0.7915 - val_loss: 1.5473 - val_accuracy: 0.4935\n",
      "Epoch 943/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6795 - accuracy: 0.7848 - val_loss: 1.5560 - val_accuracy: 0.4840\n",
      "Epoch 944/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6685 - accuracy: 0.7908 - val_loss: 1.7185 - val_accuracy: 0.4690\n",
      "Epoch 945/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6709 - accuracy: 0.7882 - val_loss: 1.5705 - val_accuracy: 0.4815\n",
      "Epoch 946/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6615 - accuracy: 0.7951 - val_loss: 1.9911 - val_accuracy: 0.4330\n",
      "Epoch 947/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6748 - accuracy: 0.7877 - val_loss: 1.7420 - val_accuracy: 0.4655\n",
      "Epoch 948/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6641 - accuracy: 0.7894 - val_loss: 1.7135 - val_accuracy: 0.4800\n",
      "Epoch 949/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6651 - accuracy: 0.7909 - val_loss: 1.7709 - val_accuracy: 0.4515\n",
      "Epoch 950/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6685 - accuracy: 0.7889 - val_loss: 1.5738 - val_accuracy: 0.5145\n",
      "Epoch 951/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6615 - accuracy: 0.7909 - val_loss: 1.5189 - val_accuracy: 0.5135\n",
      "Epoch 952/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6703 - accuracy: 0.7873 - val_loss: 2.4166 - val_accuracy: 0.3785\n",
      "Epoch 953/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6852 - accuracy: 0.7830 - val_loss: 1.5936 - val_accuracy: 0.4860\n",
      "Epoch 954/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6636 - accuracy: 0.7903 - val_loss: 1.6037 - val_accuracy: 0.4865\n",
      "Epoch 955/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6532 - accuracy: 0.8002 - val_loss: 1.7479 - val_accuracy: 0.4695\n",
      "Epoch 956/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6535 - accuracy: 0.7977 - val_loss: 1.4709 - val_accuracy: 0.5195\n",
      "Epoch 957/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6522 - accuracy: 0.7964 - val_loss: 1.4819 - val_accuracy: 0.5120\n",
      "Epoch 958/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6470 - accuracy: 0.8038 - val_loss: 1.5677 - val_accuracy: 0.4945\n",
      "Epoch 959/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6515 - accuracy: 0.7979 - val_loss: 1.9514 - val_accuracy: 0.4445\n",
      "Epoch 960/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6538 - accuracy: 0.7968 - val_loss: 1.5445 - val_accuracy: 0.4985\n",
      "Epoch 961/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6527 - accuracy: 0.7960 - val_loss: 1.5620 - val_accuracy: 0.4915\n",
      "Epoch 962/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6446 - accuracy: 0.8005 - val_loss: 1.8020 - val_accuracy: 0.4615\n",
      "Epoch 963/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6502 - accuracy: 0.7948 - val_loss: 1.4802 - val_accuracy: 0.5115\n",
      "Epoch 964/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6406 - accuracy: 0.8000 - val_loss: 1.8226 - val_accuracy: 0.4430\n",
      "Epoch 965/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6491 - accuracy: 0.7967 - val_loss: 1.4852 - val_accuracy: 0.5185\n",
      "Epoch 966/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6435 - accuracy: 0.7980 - val_loss: 1.9969 - val_accuracy: 0.4405\n",
      "Epoch 967/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6488 - accuracy: 0.8009 - val_loss: 1.6870 - val_accuracy: 0.4675\n",
      "Epoch 968/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6366 - accuracy: 0.8025 - val_loss: 1.7719 - val_accuracy: 0.4535\n",
      "Epoch 969/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6385 - accuracy: 0.8037 - val_loss: 1.8033 - val_accuracy: 0.4475\n",
      "Epoch 970/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6396 - accuracy: 0.8038 - val_loss: 1.6181 - val_accuracy: 0.4855\n",
      "Epoch 971/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6291 - accuracy: 0.8032 - val_loss: 1.5159 - val_accuracy: 0.5150\n",
      "Epoch 972/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6322 - accuracy: 0.8062 - val_loss: 1.6128 - val_accuracy: 0.4815\n",
      "Epoch 973/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6348 - accuracy: 0.8024 - val_loss: 1.8002 - val_accuracy: 0.4650\n",
      "Epoch 974/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6360 - accuracy: 0.8038 - val_loss: 1.7070 - val_accuracy: 0.4830\n",
      "Epoch 975/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6334 - accuracy: 0.8052 - val_loss: 1.7476 - val_accuracy: 0.4665\n",
      "Epoch 976/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6302 - accuracy: 0.8069 - val_loss: 1.5131 - val_accuracy: 0.5190\n",
      "Epoch 977/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6313 - accuracy: 0.8025 - val_loss: 1.5101 - val_accuracy: 0.5155\n",
      "Epoch 978/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6316 - accuracy: 0.8039 - val_loss: 2.1623 - val_accuracy: 0.4130\n",
      "Epoch 979/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6395 - accuracy: 0.8008 - val_loss: 1.6269 - val_accuracy: 0.5055\n",
      "Epoch 980/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6225 - accuracy: 0.8094 - val_loss: 1.5462 - val_accuracy: 0.4950\n",
      "Epoch 981/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6317 - accuracy: 0.7997 - val_loss: 1.5652 - val_accuracy: 0.5185\n",
      "Epoch 982/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6323 - accuracy: 0.8004 - val_loss: 1.6515 - val_accuracy: 0.4800\n",
      "Epoch 983/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6190 - accuracy: 0.8079 - val_loss: 1.8614 - val_accuracy: 0.4450\n",
      "Epoch 984/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6263 - accuracy: 0.8080 - val_loss: 1.8439 - val_accuracy: 0.4765\n",
      "Epoch 985/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6245 - accuracy: 0.8122 - val_loss: 1.9286 - val_accuracy: 0.4205\n",
      "Epoch 986/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6276 - accuracy: 0.8103 - val_loss: 1.8355 - val_accuracy: 0.4615\n",
      "Epoch 987/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6269 - accuracy: 0.8102 - val_loss: 1.5652 - val_accuracy: 0.5015\n",
      "Epoch 988/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6252 - accuracy: 0.8064 - val_loss: 2.0242 - val_accuracy: 0.3970\n",
      "Epoch 989/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6211 - accuracy: 0.8097 - val_loss: 1.5280 - val_accuracy: 0.5185\n",
      "Epoch 990/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6103 - accuracy: 0.8154 - val_loss: 1.7627 - val_accuracy: 0.4810\n",
      "Epoch 991/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6065 - accuracy: 0.8186 - val_loss: 1.4787 - val_accuracy: 0.5225\n",
      "Epoch 992/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6143 - accuracy: 0.8102 - val_loss: 1.5741 - val_accuracy: 0.5130\n",
      "Epoch 993/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6105 - accuracy: 0.8116 - val_loss: 1.8177 - val_accuracy: 0.4590\n",
      "Epoch 994/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6109 - accuracy: 0.8147 - val_loss: 1.5273 - val_accuracy: 0.5195\n",
      "Epoch 995/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6046 - accuracy: 0.8203 - val_loss: 1.5070 - val_accuracy: 0.5195\n",
      "Epoch 996/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6108 - accuracy: 0.8115 - val_loss: 1.6834 - val_accuracy: 0.5010\n",
      "Epoch 997/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6058 - accuracy: 0.8152 - val_loss: 1.4975 - val_accuracy: 0.5180\n",
      "Epoch 998/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6010 - accuracy: 0.8208 - val_loss: 2.1860 - val_accuracy: 0.4125\n",
      "Epoch 999/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6167 - accuracy: 0.8121 - val_loss: 1.5835 - val_accuracy: 0.4940\n",
      "Epoch 1000/1000\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.6023 - accuracy: 0.8208 - val_loss: 1.5258 - val_accuracy: 0.5175\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./models/90_100_SGD_no_dropout/assets\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DznImZ8pEVrK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMjSLce81jpYsp5N+lmaM7E",
   "collapsed_sections": [],
   "name": "Mu_Siyi_TaskA_qn1(GPU).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
